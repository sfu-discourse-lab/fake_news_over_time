{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfSzZmVVg_f3"
   },
   "source": [
    "# Notebook for Finding Ngrams\n",
    "\n",
    "Using scikit-learn, we want to find ngrams (most commonly occuring sets of words) in the articles across each year.\n",
    "\n",
    "Currently processes the \"Fakespeak-ENG modified.xlsx\" file (I've renamed my copy to \"Fakespeak_ENG_modified.xlsx\" to create a more consistent path), but will eventually be run on data from MisInfoText as well.\n",
    "\n",
    "From the original data file, we use the following columns: ID, combinedLabel, originalTextType, originalBodyText, originalDateYear\n",
    "\n",
    "We are processing text from the \"originalBodyText\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3972,
     "status": "ok",
     "timestamp": 1734639663601,
     "user": {
      "displayName": "Jodie Lee",
      "userId": "05117498454440747132"
     },
     "user_tz": 480
    },
    "id": "DZ6Pu-lugDAx"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18372,
     "status": "ok",
     "timestamp": 1734639705185,
     "user": {
      "displayName": "Jodie Lee",
      "userId": "05117498454440747132"
     },
     "user_tz": 480
    },
    "id": "MhB8SY_NhtDW",
    "outputId": "f263dea7-611c-498f-d6aa-393f1cb322a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEFouFkvhwr2"
   },
   "source": [
    "## Load in fakespeak dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetConfig():\n",
    "    input_path: str\n",
    "    output_path: str\n",
    "    output_path_headlines: str\n",
    "    sheet_name: str\n",
    "    usecols: list[str]\n",
    "\n",
    "    def __init__(self, input_path: str, output_path: str, output_path_headlines: str, sheet_name: str, usecols: list[str]):\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "        self.output_path_headlines = output_path_headlines\n",
    "        self.sheet_name = sheet_name\n",
    "        self.usecols = usecols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakespeak_config = DatasetConfig(\n",
    "    # file_path=\"/content/drive/My Drive/fake_news_over_time/Fakespeak_ENG_modified.xlsx\",\n",
    "    input_path=\"./data/Fakespeak-ENG/Fakespeak-ENG modified.xlsx\",\n",
    "    output_path=\"./data/Fakespeak-ENG/Analysis_output/Fakespeak_ngrams.xlsx\",\n",
    "    output_path_headlines=\"./data/Fakespeak-ENG/Analysis_output/Fakespeak_ngrams_headlines.xlsx\",\n",
    "    sheet_name=\"Working\",\n",
    "    usecols=['ID', 'combinedLabel', 'originalTextType', 'originalBodyText', 'originalDateYear', 'originalHeadline']\n",
    ")\n",
    "\n",
    "misinfotext_config = DatasetConfig(\n",
    "    input_path=\"./data/MisInfoText/PolitiFact_original_modified.xlsx\",\n",
    "    output_path=\"./data/MisInfoText/Analysis_output/MisInfoText_ngrams.xlsx\",\n",
    "    output_path_headlines=\"./data/MisInfoText/Analysis_output/MisInfoText_ngrams_headlines.xlsx\",\n",
    "    sheet_name=\"Working\",\n",
    "    usecols=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_dataset = fakespeak_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 4063,
     "status": "ok",
     "timestamp": 1734639714338,
     "user": {
      "displayName": "Jodie Lee",
      "userId": "05117498454440747132"
     },
     "user_tz": 480
    },
    "id": "pETCTEaHiGSN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>combinedLabel</th>\n",
       "      <th>originalTextType</th>\n",
       "      <th>originalBodyText</th>\n",
       "      <th>originalHeadline</th>\n",
       "      <th>originalDateYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Politifact_FALSE_Social media_687276</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Mexico is paying for the Wall through the new ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Politifact_FALSE_Social media_25111</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Chuck Schumer: \"why should American citizens b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Politifact_FALSE_Social media_735424</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Billions of dollars are sent to the State of C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Politifact_FALSE_Social media_594307</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>If 50 Billion $$ were set aside to go towards ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Politifact_FALSE_Social media_839325</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Huge@#CD 9 news. \\n@ncsbe\\n sent letter to eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID combinedLabel originalTextType  \\\n",
       "0  Politifact_FALSE_Social media_687276         False     Social media   \n",
       "1   Politifact_FALSE_Social media_25111         False     Social media   \n",
       "2  Politifact_FALSE_Social media_735424         False     Social media   \n",
       "3  Politifact_FALSE_Social media_594307         False     Social media   \n",
       "4  Politifact_FALSE_Social media_839325         False     Social media   \n",
       "\n",
       "                                    originalBodyText originalHeadline  \\\n",
       "0  Mexico is paying for the Wall through the new ...              NaN   \n",
       "1  Chuck Schumer: \"why should American citizens b...              NaN   \n",
       "2  Billions of dollars are sent to the State of C...              NaN   \n",
       "3  If 50 Billion $$ were set aside to go towards ...              NaN   \n",
       "4  Huge@#CD 9 news. \\n@ncsbe\\n sent letter to eve...              NaN   \n",
       "\n",
       "   originalDateYear  \n",
       "0              2019  \n",
       "1              2019  \n",
       "2              2019  \n",
       "3              2019  \n",
       "4              2019  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = pd.read_excel(\n",
    "    using_dataset.input_path, \n",
    "    sheet_name=using_dataset.sheet_name, \n",
    "    usecols=using_dataset.usecols\n",
    ")\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzY0GBDSk8bO"
   },
   "source": [
    "## Extracting ngrams\n",
    "\n",
    "Here we use sklearn's CountVectorizer() function to produce ngrams where n=1-5. First, we separate the fakespeak_df into its respective years, then find these ngrams and create new dataframes to hold them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1734642816321,
     "user": {
      "displayName": "Jodie Lee",
      "userId": "05117498454440747132"
     },
     "user_tz": 480
    },
    "id": "HwHfyCtfnsy-"
   },
   "outputs": [],
   "source": [
    "# helper function to find ngrams for articles from each year\n",
    "def get_ngram_counts(df: pd.DataFrame, col: str):\n",
    "  year = df[\"originalDateYear\"].iloc[0]\n",
    "  \n",
    "  # initialize vector\n",
    "  c_vec = CountVectorizer(ngram_range=(1, 5))\n",
    "\n",
    "  # input to fit_transform must be an iterable of strings\n",
    "  ngrams = c_vec.fit_transform(df[col].to_list())\n",
    "\n",
    "  # initialize vocabulary after calling fit_transform\n",
    "  vocab = c_vec.vocabulary_\n",
    "\n",
    "  count_values = ngrams.toarray().sum(axis=0)\n",
    "\n",
    "  # list to hold ngram rows that will be turned into a dataframe\n",
    "  ngram_list = []\n",
    "\n",
    "  for count, text in sorted([(count_values[i], k) for k, i in vocab.items()], reverse=True):\n",
    "    n = len(text.split())\n",
    "    ngram_list.append([n, text, count, year])\n",
    "\n",
    "  headers = ['n', 'ngram_text', 'ngram_count', 'year']\n",
    "  ngram_df = pd.DataFrame(ngram_list, columns=headers)\n",
    "\n",
    "  # sort the dataframe by n\n",
    "  ngram_df = ngram_df.sort_values(by=['n', 'ngram_count'], ascending=[True, False])\n",
    "\n",
    "  return ngram_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 28824,
     "status": "ok",
     "timestamp": 1734644387254,
     "user": {
      "displayName": "Jodie Lee",
      "userId": "05117498454440747132"
     },
     "user_tz": 480
    },
    "id": "aRFk3uJMk_O2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>ngram_text</th>\n",
       "      <th>ngram_count</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>1580</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>to</td>\n",
       "      <td>1009</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>852</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>752</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>580</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115070</th>\n",
       "      <td>5</td>\n",
       "      <td>000 according to regional data</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115074</th>\n",
       "      <td>5</td>\n",
       "      <td>000 000 that have been</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115078</th>\n",
       "      <td>5</td>\n",
       "      <td>00 to the trump campaign</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115082</th>\n",
       "      <td>5</td>\n",
       "      <td>00 ticket and you will</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115086</th>\n",
       "      <td>5</td>\n",
       "      <td>00 they have not posted</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115090 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        n                      ngram_text  ngram_count  year\n",
       "0       1                             the         1580  2019\n",
       "1       1                              to         1009  2019\n",
       "2       1                             and          852  2019\n",
       "3       1                              of          752  2019\n",
       "4       1                              in          580  2019\n",
       "...    ..                             ...          ...   ...\n",
       "115070  5  000 according to regional data            1  2019\n",
       "115074  5          000 000 that have been            1  2019\n",
       "115078  5        00 to the trump campaign            1  2019\n",
       "115082  5          00 ticket and you will            1  2019\n",
       "115086  5         00 they have not posted            1  2019\n",
       "\n",
       "[115090 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get ngrams for each year\n",
    "grouped_by_year = dataset_df.groupby(by=\"originalDateYear\")\n",
    "ngram_years_dfs = [get_ngram_counts(grouped_by_year.get_group(group), \"originalBodyText\") \n",
    "                   for group in grouped_by_year.groups]\n",
    "ngram_years_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>ngram_text</th>\n",
       "      <th>ngram_count</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>1580</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>to</td>\n",
       "      <td>1009</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>852</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>752</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>580</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115070</th>\n",
       "      <td>5</td>\n",
       "      <td>000 according to regional data</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115074</th>\n",
       "      <td>5</td>\n",
       "      <td>000 000 that have been</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115078</th>\n",
       "      <td>5</td>\n",
       "      <td>00 to the trump campaign</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115082</th>\n",
       "      <td>5</td>\n",
       "      <td>00 ticket and you will</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115086</th>\n",
       "      <td>5</td>\n",
       "      <td>00 they have not posted</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115090 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        n                      ngram_text  ngram_count  year\n",
       "0       1                             the         1580  2019\n",
       "1       1                              to         1009  2019\n",
       "2       1                             and          852  2019\n",
       "3       1                              of          752  2019\n",
       "4       1                              in          580  2019\n",
       "...    ..                             ...          ...   ...\n",
       "115070  5  000 according to regional data            1  2019\n",
       "115074  5          000 000 that have been            1  2019\n",
       "115078  5        00 to the trump campaign            1  2019\n",
       "115082  5          00 ticket and you will            1  2019\n",
       "115086  5         00 they have not posted            1  2019\n",
       "\n",
       "[115090 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_by_year_headlines = dataset_df.groupby(by=\"originalDateYear\")\n",
    "ngram_years_headlines_dfs = [get_ngram_counts(grouped_by_year.get_group(group), \"originalBodyText\") \n",
    "                             for group in grouped_by_year_headlines.groups]\n",
    "ngram_years_headlines_dfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPOVdIvRzR1G"
   },
   "source": [
    "## Prepare dataframes to output to spreadsheet\n",
    "Currently, the dataframes hold all found ngrams with n=1-5, including ones that only appear once (which isn't very helpful - for reference, the unfiltered 2019 dataframe contains 115,090 entries). To address this issue, we only take the first 20 entries for each n=2-5 (i.e. we take the first 20 bigrams, then the first 20 trigrams, etc. for each year).\n",
    "\n",
    "The exception is we take the first 50 monogram entries, since a lot of them tend to be common words and the results are more interesting when we broaden the search. To circumvent this, we also drop the first 10 rows from each dataframe to go further down the monogram list (this can also be adjusted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1734645940563,
     "user": {
      "displayName": "Jodie Lee",
      "userId": "05117498454440747132"
     },
     "user_tz": 480
    },
    "id": "w7FzGJgQ0ht_"
   },
   "outputs": [],
   "source": [
    "# helper function that cleans up the dataframes as outlined above\n",
    "# where df is the ngram dataframe\n",
    "# num_mono is the number of entries to include for monograms\n",
    "# num_other is the number of entries to include for the other ngrams\n",
    "# drop index indicates the number of rows we want to drop from the top of the dataframe\n",
    "def clean_ngram(df, num_mono, num_other, drop_index):\n",
    "  # drop 20 most common ngrams\n",
    "  df = df.iloc[drop_index:]\n",
    "\n",
    "  # filter dataframe by ngram frequency\n",
    "  df1 = df[df['n'] == 1].head(num_mono)\n",
    "  df2 = df[df['n'] == 2].head(num_other)\n",
    "  df3 = df[df['n'] == 3].head(num_other)\n",
    "  df4 = df[df['n'] == 4].head(num_other)\n",
    "  df5 = df[df['n'] == 5].head(num_other)\n",
    "\n",
    "  # concatenate the dataframes along the rows\n",
    "  output_df = pd.concat([df1, df2, df3, df4, df5], axis=0)\n",
    "\n",
    "  return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 782,
     "status": "ok",
     "timestamp": 1734645943668,
     "user": {
      "displayName": "Jodie Lee",
      "userId": "05117498454440747132"
     },
     "user_tz": 480
    },
    "id": "TVPwLXRrq8TW"
   },
   "outputs": [],
   "source": [
    "num_entries_mono = 50\n",
    "num_entries_other = 20\n",
    "drop_index = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>ngram_text</th>\n",
       "      <th>ngram_count</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>on</td>\n",
       "      <td>221</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>we</td>\n",
       "      <td>217</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>are</td>\n",
       "      <td>208</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>you</td>\n",
       "      <td>196</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>with</td>\n",
       "      <td>189</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>5</td>\n",
       "      <td>sen cruz said to the</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>5</td>\n",
       "      <td>or technique capable of causing</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>5</td>\n",
       "      <td>or incendiary device or technique</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>5</td>\n",
       "      <td>of any firearm explosive or</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>5</td>\n",
       "      <td>most manufacturing jobs in the</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n                         ngram_text  ngram_count  year\n",
       "10    1                                 on          221  2019\n",
       "11    1                                 we          217  2019\n",
       "12    1                                are          208  2019\n",
       "13    1                                you          196  2019\n",
       "14    1                               with          189  2019\n",
       "...  ..                                ...          ...   ...\n",
       "2602  5               sen cruz said to the            3  2019\n",
       "2749  5    or technique capable of causing            3  2019\n",
       "2755  5  or incendiary device or technique            3  2019\n",
       "2801  5        of any firearm explosive or            3  2019\n",
       "2842  5     most manufacturing jobs in the            3  2019\n",
       "\n",
       "[130 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ngram_years_dfs = [clean_ngram(df, num_entries_mono, num_entries_other, drop_index) \n",
    "                         for df in ngram_years_dfs]\n",
    "clean_ngram_years_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1734645962792,
     "user": {
      "displayName": "Jodie Lee",
      "userId": "05117498454440747132"
     },
     "user_tz": 480
    },
    "id": "fhBqJxSt2y0-",
    "outputId": "1183da9d-e575-42fc-f927-cc2ec0281f38"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>ngram_text</th>\n",
       "      <th>ngram_count</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>on</td>\n",
       "      <td>221</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>we</td>\n",
       "      <td>217</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>are</td>\n",
       "      <td>208</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>you</td>\n",
       "      <td>196</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>with</td>\n",
       "      <td>189</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>5</td>\n",
       "      <td>sen cruz said to the</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>5</td>\n",
       "      <td>or technique capable of causing</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>5</td>\n",
       "      <td>or incendiary device or technique</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>5</td>\n",
       "      <td>of any firearm explosive or</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>5</td>\n",
       "      <td>most manufacturing jobs in the</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n                         ngram_text  ngram_count  year\n",
       "10    1                                 on          221  2019\n",
       "11    1                                 we          217  2019\n",
       "12    1                                are          208  2019\n",
       "13    1                                you          196  2019\n",
       "14    1                               with          189  2019\n",
       "...  ..                                ...          ...   ...\n",
       "2602  5               sen cruz said to the            3  2019\n",
       "2749  5    or technique capable of causing            3  2019\n",
       "2755  5  or incendiary device or technique            3  2019\n",
       "2801  5        of any firearm explosive or            3  2019\n",
       "2842  5     most manufacturing jobs in the            3  2019\n",
       "\n",
       "[130 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ngram_years_headlines_dfs = [clean_ngram(df, num_entries_mono, num_entries_other, drop_index) \n",
    "                                   for df in ngram_years_headlines_dfs]\n",
    "clean_ngram_years_headlines_dfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBMhLeeD3s9r"
   },
   "source": [
    "We could show the resulting dataframes for the other years as well, but here I've chosen not to in order to save space and improve readability for the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJUd0Gyh3rpe"
   },
   "source": [
    "## Write dataframes to excel spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "st2GB47-4AAN"
   },
   "outputs": [],
   "source": [
    "!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 1024,
     "status": "ok",
     "timestamp": 1734645980648,
     "user": {
      "displayName": "Jodie Lee",
      "userId": "05117498454440747132"
     },
     "user_tz": 480
    },
    "id": "vYC-AUPt4H5-"
   },
   "outputs": [],
   "source": [
    "# create excel writer object to initialize new workbook\n",
    "writer = pd.ExcelWriter(using_dataset.output_path, engine=\"xlsxwriter\")\n",
    "\n",
    "for df in clean_ngram_years_dfs:\n",
    "    year = str(df[\"year\"].iloc[0])\n",
    "    columns_to_save = [col for col in df.columns if col != \"year\"]\n",
    "    df.to_excel(writer, sheet_name=year, columns=columns_to_save, index=False)\n",
    "\n",
    "# close the excel writer and output file\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create excel writer object to initialize new workbook\n",
    "writer = pd.ExcelWriter(using_dataset.output_path_headlines, engine=\"xlsxwriter\")\n",
    "\n",
    "for df in clean_ngram_years_headlines_dfs:\n",
    "    year = str(df[\"year\"].iloc[0])\n",
    "    columns_to_save = [col for col in df.columns if col != \"year\"]\n",
    "    df.to_excel(writer, sheet_name=year, columns=columns_to_save, index=False)\n",
    "\n",
    "# close the excel writer and output file\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP7OonnWjvEWZsKD567Kb1t",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
