{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfSzZmVVg_f3"
   },
   "source": [
    "# Notebook for Finding Ngrams\n",
    "\n",
    "Using scikit-learn, we want to find ngrams (most commonly occuring sets of words) in the articles across each year.\n",
    "\n",
    "Currently processes the \"Fakespeak-ENG modified.xlsx\" file (I've renamed my copy to \"Fakespeak_ENG_modified.xlsx\" to create a more consistent path), but will eventually be run on data from MisInfoText as well.\n",
    "\n",
    "From the original data file, we use the following columns: ID, combinedLabel, originalTextType, originalBodyText, originalDateYear\n",
    "\n",
    "We are processing text from the \"originalBodyText\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18372,
     "status": "ok",
     "timestamp": 1734639705185,
     "user": {
      "displayName": "Jodie Lee",
      "userId": "05117498454440747132"
     },
     "user_tz": 480
    },
    "id": "MhB8SY_NhtDW",
    "outputId": "f263dea7-611c-498f-d6aa-393f1cb322a1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 3972,
     "status": "ok",
     "timestamp": 1734639663601,
     "user": {
      "displayName": "Jodie Lee",
      "userId": "05117498454440747132"
     },
     "user_tz": 480
    },
    "id": "DZ6Pu-lugDAx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from dataset_config import BASE_FAKESPEAK_CONFIG, BASE_MISINFOTEXT_CONFIG\n",
    "from helpers import get_groups, make_output_path, make_output_path_for_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEFouFkvhwr2"
   },
   "source": [
    "## Load in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakespeak_config = BASE_FAKESPEAK_CONFIG | {\n",
    "    \"headline_col\": \"originalHeadline\",\n",
    "    \"usecols\": BASE_FAKESPEAK_CONFIG[\"usecols\"] + [\"originalHeadline\"]\n",
    "}\n",
    "\n",
    "misinfotext_config = BASE_MISINFOTEXT_CONFIG | {\n",
    "    \"headline_col\": \"originalHeadline\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_dataset = misinfotext_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 4063,
     "status": "ok",
     "timestamp": 1734639714338,
     "user": {
      "displayName": "Jodie Lee",
      "userId": "05117498454440747132"
     },
     "user_tz": 480
    },
    "id": "pETCTEaHiGSN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factcheckURL</th>\n",
       "      <th>originalURL</th>\n",
       "      <th>originalBodyText</th>\n",
       "      <th>originalHeadline</th>\n",
       "      <th>originalTextType</th>\n",
       "      <th>originalDate</th>\n",
       "      <th>originalDateYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.politifact.com/arizona/statements/2...</td>\n",
       "      <td>https://associatedmediacoverage.com/three-stat...</td>\n",
       "      <td>Residents of multiple states will be asked to ...</td>\n",
       "      <td>Multiple States Have Agreed To Implement A ‘Tw...</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>2016-05-06</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>https://users.focalbeam.com/fs/distribution:wl...</td>\n",
       "      <td>Sacramento, CA - United States Senator Dianne ...</td>\n",
       "      <td>U.S. Senator Dianne Feinstein Opposes Prop. 64...</td>\n",
       "      <td>Press release</td>\n",
       "      <td>2016-07-12</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>http://www.sacbee.com/opinion/op-ed/soapbox/ar...</td>\n",
       "      <td>We should anticipate black and gray markets in...</td>\n",
       "      <td>Why you should buy a locking gasoline cap</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>https://nocagastax.com/california-gas-tax-hike...</td>\n",
       "      <td>As a ballot initiative calling for repeal of a...</td>\n",
       "      <td>California Gas-Tax-Hike Repeal Campaign Heats Up</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>2017-06-15</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>https://chu.house.gov/media-center/press-relea...</td>\n",
       "      <td>WASHINGTON, DC  The House of Representatives t...</td>\n",
       "      <td>Rep. Chu Decries \"Heartless\" ACA Repeal Vote</td>\n",
       "      <td>Press release</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        factcheckURL  \\\n",
       "0  http://www.politifact.com/arizona/statements/2...   \n",
       "1  http://www.politifact.com/california/statement...   \n",
       "2  http://www.politifact.com/california/statement...   \n",
       "3  http://www.politifact.com/california/statement...   \n",
       "4  http://www.politifact.com/california/statement...   \n",
       "\n",
       "                                         originalURL  \\\n",
       "0  https://associatedmediacoverage.com/three-stat...   \n",
       "1  https://users.focalbeam.com/fs/distribution:wl...   \n",
       "2  http://www.sacbee.com/opinion/op-ed/soapbox/ar...   \n",
       "3  https://nocagastax.com/california-gas-tax-hike...   \n",
       "4  https://chu.house.gov/media-center/press-relea...   \n",
       "\n",
       "                                    originalBodyText  \\\n",
       "0  Residents of multiple states will be asked to ...   \n",
       "1  Sacramento, CA - United States Senator Dianne ...   \n",
       "2  We should anticipate black and gray markets in...   \n",
       "3  As a ballot initiative calling for repeal of a...   \n",
       "4  WASHINGTON, DC  The House of Representatives t...   \n",
       "\n",
       "                                    originalHeadline originalTextType  \\\n",
       "0  Multiple States Have Agreed To Implement A ‘Tw...    News and blog   \n",
       "1  U.S. Senator Dianne Feinstein Opposes Prop. 64...    Press release   \n",
       "2          Why you should buy a locking gasoline cap    News and blog   \n",
       "3   California Gas-Tax-Hike Repeal Campaign Heats Up    News and blog   \n",
       "4       Rep. Chu Decries \"Heartless\" ACA Repeal Vote    Press release   \n",
       "\n",
       "  originalDate  originalDateYear  \n",
       "0   2016-05-06              2016  \n",
       "1   2016-07-12              2016  \n",
       "2   2017-08-04              2017  \n",
       "3   2017-06-15              2017  \n",
       "4   2017-05-04              2017  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = pd.read_excel(\n",
    "    using_dataset[\"input_path\"], \n",
    "    sheet_name=using_dataset[\"sheet_name\"], \n",
    "    usecols=using_dataset[\"usecols\"]\n",
    ")\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzY0GBDSk8bO"
   },
   "source": [
    "## Extracting ngrams\n",
    "\n",
    "Here we use sklearn's CountVectorizer() function to produce ngrams where n=1-5. First, we separate the fakespeak_df into its respective years, then find these ngrams and create new dataframes to hold them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1734642816321,
     "user": {
      "displayName": "Jodie Lee",
      "userId": "05117498454440747132"
     },
     "user_tz": 480
    },
    "id": "HwHfyCtfnsy-"
   },
   "outputs": [],
   "source": [
    "# helper function to find ngrams for articles from each year\n",
    "def get_ngram_counts(df: pd.DataFrame, col: str):\n",
    "  # initialize vector\n",
    "  c_vec = CountVectorizer(ngram_range=(1, 5))\n",
    "\n",
    "  # input to fit_transform must be an iterable of strings\n",
    "  ngrams = c_vec.fit_transform(df[col].to_list())\n",
    "\n",
    "  # initialize vocabulary after calling fit_transform\n",
    "  vocab = c_vec.vocabulary_\n",
    "\n",
    "  count_values = ngrams.toarray().sum(axis=0)\n",
    "\n",
    "  # list to hold ngram rows that will be turned into a dataframe\n",
    "  ngram_list = []\n",
    "\n",
    "  for count, text in sorted([(count_values[i], k) for k, i in vocab.items()], reverse=True):\n",
    "    n = len(text.split())\n",
    "    ngram_list.append([n, text, count])\n",
    "\n",
    "  headers = ['n', 'ngram_text', 'ngram_count']\n",
    "  ngram_df = pd.DataFrame(ngram_list, columns=headers)\n",
    "\n",
    "  # sort the dataframe by n\n",
    "  ngram_df = ngram_df.sort_values(by=['n', 'ngram_count'], ascending=[True, False])\n",
    "\n",
    "  return ngram_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPOVdIvRzR1G"
   },
   "source": [
    "## Prepare dataframes to output to spreadsheet\n",
    "Currently, the dataframes hold all found ngrams with n=1-5, including ones that only appear once (which isn't very helpful - for reference, the unfiltered 2019 dataframe contains 115,090 entries). To address this issue, we only take the first 20 entries for each n=2-5 (i.e. we take the first 20 bigrams, then the first 20 trigrams, etc. for each year).\n",
    "\n",
    "The exception is we take the first 50 monogram entries, since a lot of them tend to be common words and the results are more interesting when we broaden the search. To circumvent this, we also drop the first 10 rows from each dataframe to go further down the monogram list (this can also be adjusted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1734645940563,
     "user": {
      "displayName": "Jodie Lee",
      "userId": "05117498454440747132"
     },
     "user_tz": 480
    },
    "id": "w7FzGJgQ0ht_"
   },
   "outputs": [],
   "source": [
    "# helper function that cleans up the dataframes as outlined above\n",
    "# where df is the ngram dataframe\n",
    "# num_mono is the number of entries to include for monograms\n",
    "# num_other is the number of entries to include for the other ngrams\n",
    "# drop index indicates the number of rows we want to drop from the top of the dataframe\n",
    "def clean_ngram(df: pd.DataFrame, num_mono=50, num_other=20, drop_index=10):\n",
    "  # drop 20 most common ngrams\n",
    "  df = df.iloc[drop_index:]\n",
    "\n",
    "  # filter dataframe by ngram frequency\n",
    "  df1 = df[df['n'] == 1].head(num_mono)\n",
    "  df2 = df[df['n'] == 2].head(num_other)\n",
    "  df3 = df[df['n'] == 3].head(num_other)\n",
    "  df4 = df[df['n'] == 4].head(num_other)\n",
    "  df5 = df[df['n'] == 5].head(num_other)\n",
    "\n",
    "  # concatenate the dataframes along the rows\n",
    "  output_df = pd.concat([df1, df2, df3, df4, df5], axis=0)\n",
    "\n",
    "  return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram_years_dfs(df: pd.DataFrame):\n",
    "    years, years_dfs = get_groups(df, using_dataset[\"year_col\"])\n",
    "    headline_years_df = [df[~df[using_dataset[\"headline_col\"]].isna()] for df in years_dfs]\n",
    "    \n",
    "    ngrams_text_years_dfs = [clean_ngram(get_ngram_counts(df, using_dataset[\"text_col\"])) for df in years_dfs]\n",
    "    ngrams_headline_years_dfs = [clean_ngram(get_ngram_counts(df, using_dataset[\"headline_col\"])) for df in headline_years_df]\n",
    "    \n",
    "    return years, ngrams_text_years_dfs, ngrams_headline_years_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "years, ngrams_text_years_dfs, ngrams_headline_years_dfs = get_ngram_years_dfs(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>ngram_text</th>\n",
       "      <th>ngram_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>an</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>we</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>surge</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>new</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n  ngram_text  ngram_count\n",
       "10  1          an            3\n",
       "11  1  withdrawal            2\n",
       "12  1          we            2\n",
       "17  1       surge            2\n",
       "20  1         new            2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_text_years_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>ngram_text</th>\n",
       "      <th>ngram_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>john mccain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>hillary clinton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>by john</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>statement by john</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>on hillary clinton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n          ngram_text  ngram_count\n",
       "15  2         john mccain            1\n",
       "17  2     hillary clinton            1\n",
       "23  2             by john            1\n",
       "2   3   statement by john            1\n",
       "5   3  on hillary clinton            1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_headline_years_dfs[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBMhLeeD3s9r"
   },
   "source": [
    "We could show the resulting dataframes for the other years as well, but here I've chosen not to in order to save space and improve readability for the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJUd0Gyh3rpe"
   },
   "source": [
    "## Write dataframes to excel spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = make_output_path(using_dataset, \"ngrams\")\n",
    "\n",
    "writer = pd.ExcelWriter(output_path, engine=\"xlsxwriter\")\n",
    "\n",
    "for year, df in zip(years, ngrams_text_years_dfs):\n",
    "    df.to_excel(writer, sheet_name=str(year), index=False)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = make_output_path(using_dataset, \"ngrams_headlines\")\n",
    "\n",
    "writer = pd.ExcelWriter(output_path, engine=\"xlsxwriter\")\n",
    "\n",
    "for year, df in zip(years, ngrams_headline_years_dfs):\n",
    "    df.to_excel(writer, sheet_name=str(year), index=False)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the same analysis for each separate text type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "types, types_dfs = get_groups(dataset_df, using_dataset[\"type_col\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type, df in zip(types, types_dfs):\n",
    "    years, ngrams_text_years_dfs, ngrams_headline_years_dfs = get_ngram_years_dfs(dataset_df)\n",
    "\n",
    "    output_path = make_output_path_for_type(using_dataset, type, \"ngrams\")\n",
    "\n",
    "    writer = pd.ExcelWriter(output_path, engine=\"xlsxwriter\")\n",
    "\n",
    "    for year, df in zip(years, ngrams_text_years_dfs):\n",
    "        df.to_excel(writer, sheet_name=str(year), index=False)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    output_path = make_output_path_for_type(using_dataset, type, \"ngrams_headlines\")\n",
    "\n",
    "    writer = pd.ExcelWriter(output_path, engine=\"xlsxwriter\")\n",
    "\n",
    "    for year, df in zip(years, ngrams_headline_years_dfs):\n",
    "        df.to_excel(writer, sheet_name=str(year), index=False)\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP7OonnWjvEWZsKD567Kb1t",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
