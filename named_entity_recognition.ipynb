{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLPAMQpsoQhN"
   },
   "source": [
    "# Notebook for Named Entity Recognition\n",
    "\n",
    "Using spaCy for named entity recognition, we want to create relative frequency tables for the entities by year. At this point, we are only interested in the entities that appear most frequently.\n",
    "\n",
    "Currently processes the \"Fakespeak-ENG modified.xlsx\" file (I've renamed my copy to \"Fakespeak_ENG_modified.xlsx\" to create a more consistent path), but will eventually be run on data from MisInfoText as well.\n",
    "\n",
    "From the original data file, we use the following columns: ID, combinedLabel, originalTextType, originalBodyText, originalDateYear\n",
    "\n",
    "We are processing text from the \"originalBodyText\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QC2bXdxK2nxV"
   },
   "outputs": [],
   "source": [
    "!pip install \"spacy~=3.0.6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sr1ZDOEi3-Xb"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZSqg2PnnR0u"
   },
   "outputs": [],
   "source": [
    "!pip install spacy-entity-linker==1.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DIZ26YGcpqYO"
   },
   "outputs": [],
   "source": [
    "!python -m spacy_entity_linker \"download_knowledge_base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "or0rhDkgmaVI"
   },
   "outputs": [],
   "source": [
    "# Only run this code if you're loading from Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ko3T7YsrkxJM"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from dataset_config import BASE_FAKESPEAK_CONFIG, BASE_MISINFOTEXT_CONFIG\n",
    "from helpers import get_groups, make_output_path, make_output_path_for_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-SwD9Clo1Lz"
   },
   "source": [
    "## Loading the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakespeak_config = BASE_FAKESPEAK_CONFIG | {\n",
    "    \"headline_col\": \"originalHeadline\",\n",
    "    \"usecols\": BASE_FAKESPEAK_CONFIG[\"usecols\"] + [\"originalHeadline\"]\n",
    "}\n",
    "\n",
    "misinfotext_config = BASE_MISINFOTEXT_CONFIG | {\n",
    "    \"headline_col\": \"originalHeadline\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_dataset = misinfotext_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rVQAdSteo7QM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factcheckURL</th>\n",
       "      <th>originalURL</th>\n",
       "      <th>originalBodyText</th>\n",
       "      <th>originalHeadline</th>\n",
       "      <th>originalTextType</th>\n",
       "      <th>originalDate</th>\n",
       "      <th>originalDateYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.politifact.com/arizona/statements/2...</td>\n",
       "      <td>https://associatedmediacoverage.com/three-stat...</td>\n",
       "      <td>Residents of multiple states will be asked to ...</td>\n",
       "      <td>Multiple States Have Agreed To Implement A ‘Tw...</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>2016-05-06</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>https://users.focalbeam.com/fs/distribution:wl...</td>\n",
       "      <td>Sacramento, CA - United States Senator Dianne ...</td>\n",
       "      <td>U.S. Senator Dianne Feinstein Opposes Prop. 64...</td>\n",
       "      <td>Press release</td>\n",
       "      <td>2016-07-12</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>http://www.sacbee.com/opinion/op-ed/soapbox/ar...</td>\n",
       "      <td>We should anticipate black and gray markets in...</td>\n",
       "      <td>Why you should buy a locking gasoline cap</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>https://nocagastax.com/california-gas-tax-hike...</td>\n",
       "      <td>As a ballot initiative calling for repeal of a...</td>\n",
       "      <td>California Gas-Tax-Hike Repeal Campaign Heats Up</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>2017-06-15</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>https://chu.house.gov/media-center/press-relea...</td>\n",
       "      <td>WASHINGTON, DC  The House of Representatives t...</td>\n",
       "      <td>Rep. Chu Decries \"Heartless\" ACA Repeal Vote</td>\n",
       "      <td>Press release</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        factcheckURL  \\\n",
       "0  http://www.politifact.com/arizona/statements/2...   \n",
       "1  http://www.politifact.com/california/statement...   \n",
       "2  http://www.politifact.com/california/statement...   \n",
       "3  http://www.politifact.com/california/statement...   \n",
       "4  http://www.politifact.com/california/statement...   \n",
       "\n",
       "                                         originalURL  \\\n",
       "0  https://associatedmediacoverage.com/three-stat...   \n",
       "1  https://users.focalbeam.com/fs/distribution:wl...   \n",
       "2  http://www.sacbee.com/opinion/op-ed/soapbox/ar...   \n",
       "3  https://nocagastax.com/california-gas-tax-hike...   \n",
       "4  https://chu.house.gov/media-center/press-relea...   \n",
       "\n",
       "                                    originalBodyText  \\\n",
       "0  Residents of multiple states will be asked to ...   \n",
       "1  Sacramento, CA - United States Senator Dianne ...   \n",
       "2  We should anticipate black and gray markets in...   \n",
       "3  As a ballot initiative calling for repeal of a...   \n",
       "4  WASHINGTON, DC  The House of Representatives t...   \n",
       "\n",
       "                                    originalHeadline originalTextType  \\\n",
       "0  Multiple States Have Agreed To Implement A ‘Tw...    News and blog   \n",
       "1  U.S. Senator Dianne Feinstein Opposes Prop. 64...    Press release   \n",
       "2          Why you should buy a locking gasoline cap    News and blog   \n",
       "3   California Gas-Tax-Hike Repeal Campaign Heats Up    News and blog   \n",
       "4       Rep. Chu Decries \"Heartless\" ACA Repeal Vote    Press release   \n",
       "\n",
       "  originalDate  originalDateYear  \n",
       "0   2016-05-06              2016  \n",
       "1   2016-07-12              2016  \n",
       "2   2017-08-04              2017  \n",
       "3   2017-06-15              2017  \n",
       "4   2017-05-04              2017  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = pd.read_excel(\n",
    "    using_dataset[\"input_path\"], \n",
    "    sheet_name=using_dataset[\"sheet_name\"], \n",
    "    usecols=using_dataset[\"usecols\"]\n",
    ")\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJCyzIzTpCJ5"
   },
   "source": [
    "## Tagging named entities using spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNLzISEbA9PG"
   },
   "source": [
    "To make up for the difficulties of consolidating similar named entities, we use spaCy's large web model to ensure higher tagging accuracy in the initial NER step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEYaN28SF_L3"
   },
   "source": [
    "Documentation for entityLinker: https://github.com/egerber/spaCy-entity-linker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YAbwHHn-jAjs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adam\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\site-packages\\coreferee\\manager.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "# load spacy model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# add custom entityLinker pipeline\n",
    "entity_linker = nlp.add_pipe(\"entityLinker\", last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factcheckURL</th>\n",
       "      <th>originalURL</th>\n",
       "      <th>originalBodyText</th>\n",
       "      <th>originalHeadline</th>\n",
       "      <th>originalTextType</th>\n",
       "      <th>originalDate</th>\n",
       "      <th>originalDateYear</th>\n",
       "      <th>text_doc</th>\n",
       "      <th>headline_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.politifact.com/arizona/statements/2...</td>\n",
       "      <td>https://associatedmediacoverage.com/three-stat...</td>\n",
       "      <td>Residents of multiple states will be asked to ...</td>\n",
       "      <td>Multiple States Have Agreed To Implement A ‘Tw...</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>2016-05-06</td>\n",
       "      <td>2016</td>\n",
       "      <td>(Residents, of, multiple, states, will, be, as...</td>\n",
       "      <td>(Multiple, States, Have, Agreed, To, Implement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>https://users.focalbeam.com/fs/distribution:wl...</td>\n",
       "      <td>Sacramento, CA - United States Senator Dianne ...</td>\n",
       "      <td>U.S. Senator Dianne Feinstein Opposes Prop. 64...</td>\n",
       "      <td>Press release</td>\n",
       "      <td>2016-07-12</td>\n",
       "      <td>2016</td>\n",
       "      <td>(Sacramento, ,, CA, -, United, States, Senator...</td>\n",
       "      <td>(U.S., Senator, Dianne, Feinstein, Opposes, Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>http://www.sacbee.com/opinion/op-ed/soapbox/ar...</td>\n",
       "      <td>We should anticipate black and gray markets in...</td>\n",
       "      <td>Why you should buy a locking gasoline cap</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>2017</td>\n",
       "      <td>(We, should, anticipate, black, and, gray, mar...</td>\n",
       "      <td>(Why, you, should, buy, a, locking, gasoline, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>https://nocagastax.com/california-gas-tax-hike...</td>\n",
       "      <td>As a ballot initiative calling for repeal of a...</td>\n",
       "      <td>California Gas-Tax-Hike Repeal Campaign Heats Up</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>2017-06-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>(As, a, ballot, initiative, calling, for, repe...</td>\n",
       "      <td>(California, Gas, -, Tax, -, Hike, Repeal, Cam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>https://chu.house.gov/media-center/press-relea...</td>\n",
       "      <td>WASHINGTON, DC  The House of Representatives t...</td>\n",
       "      <td>Rep. Chu Decries \"Heartless\" ACA Repeal Vote</td>\n",
       "      <td>Press release</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>2017</td>\n",
       "      <td>(WASHINGTON, ,, DC,  , The, House, of, Represe...</td>\n",
       "      <td>(Rep., Chu, Decries, \", Heartless, \", ACA, Rep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        factcheckURL  \\\n",
       "0  http://www.politifact.com/arizona/statements/2...   \n",
       "1  http://www.politifact.com/california/statement...   \n",
       "2  http://www.politifact.com/california/statement...   \n",
       "3  http://www.politifact.com/california/statement...   \n",
       "4  http://www.politifact.com/california/statement...   \n",
       "\n",
       "                                         originalURL  \\\n",
       "0  https://associatedmediacoverage.com/three-stat...   \n",
       "1  https://users.focalbeam.com/fs/distribution:wl...   \n",
       "2  http://www.sacbee.com/opinion/op-ed/soapbox/ar...   \n",
       "3  https://nocagastax.com/california-gas-tax-hike...   \n",
       "4  https://chu.house.gov/media-center/press-relea...   \n",
       "\n",
       "                                    originalBodyText  \\\n",
       "0  Residents of multiple states will be asked to ...   \n",
       "1  Sacramento, CA - United States Senator Dianne ...   \n",
       "2  We should anticipate black and gray markets in...   \n",
       "3  As a ballot initiative calling for repeal of a...   \n",
       "4  WASHINGTON, DC  The House of Representatives t...   \n",
       "\n",
       "                                    originalHeadline originalTextType  \\\n",
       "0  Multiple States Have Agreed To Implement A ‘Tw...    News and blog   \n",
       "1  U.S. Senator Dianne Feinstein Opposes Prop. 64...    Press release   \n",
       "2          Why you should buy a locking gasoline cap    News and blog   \n",
       "3   California Gas-Tax-Hike Repeal Campaign Heats Up    News and blog   \n",
       "4       Rep. Chu Decries \"Heartless\" ACA Repeal Vote    Press release   \n",
       "\n",
       "  originalDate  originalDateYear  \\\n",
       "0   2016-05-06              2016   \n",
       "1   2016-07-12              2016   \n",
       "2   2017-08-04              2017   \n",
       "3   2017-06-15              2017   \n",
       "4   2017-05-04              2017   \n",
       "\n",
       "                                            text_doc  \\\n",
       "0  (Residents, of, multiple, states, will, be, as...   \n",
       "1  (Sacramento, ,, CA, -, United, States, Senator...   \n",
       "2  (We, should, anticipate, black, and, gray, mar...   \n",
       "3  (As, a, ballot, initiative, calling, for, repe...   \n",
       "4  (WASHINGTON, ,, DC,  , The, House, of, Represe...   \n",
       "\n",
       "                                        headline_doc  \n",
       "0  (Multiple, States, Have, Agreed, To, Implement...  \n",
       "1  (U.S., Senator, Dianne, Feinstein, Opposes, Pr...  \n",
       "2  (Why, you, should, buy, a, locking, gasoline, ...  \n",
       "3  (California, Gas, -, Tax, -, Hike, Repeal, Cam...  \n",
       "4  (Rep., Chu, Decries, \", Heartless, \", ACA, Rep...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[\"text_doc\"] = list(nlp.pipe(dataset_df[using_dataset[\"text_col\"]]))\n",
    "dataset_df[\"headline_doc\"] = list(nlp.pipe(dataset_df[using_dataset[\"headline_col\"]].fillna(\"\")))\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reason, any spans of just \"President\" (or similar)\n",
    "# get tagged as Zhong Chenle, maybe because he has an alias \"President\".\n",
    "# The following code fixes that to point to the correct Wikidata entry\n",
    "# for the generic term \"president\".\n",
    "\n",
    "zhong_chenle_president_aliases = {'PRESIDENT', 'President', 'Presidents'}\n",
    "zhong_chenle_wikidata_id = 30945670\n",
    "president_wikidata_id = 30461\n",
    "\n",
    "def clean_incorrect_president_entity(df: pd.DataFrame):\n",
    "    zhong_chenle_as_president_filter = (df[\"Wikidata_id\"] == zhong_chenle_wikidata_id) & (df[\"Span_text\"].isin(zhong_chenle_president_aliases))\n",
    "    df.loc[zhong_chenle_as_president_filter, \"Entity\"] = \"president\"\n",
    "    df.loc[zhong_chenle_as_president_filter, \"Wikidata_id\"] = president_wikidata_id\n",
    "    df.loc[zhong_chenle_as_president_filter, \"Wikidata_url\"] = f\"https://www.wikidata.org/wiki/Q{president_wikidata_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A similar thing is happening where the state of Texas\n",
    "# is sometimes confused for a musical play named \"Texas\". \n",
    "\n",
    "texas_musical_wikidata_id = 7707415\n",
    "texas_state_wikidata_id = 1439\n",
    "\n",
    "def clean_incorrect_texas_entity(df: pd.DataFrame):\n",
    "    texas_musical_filter = df[\"Wikidata_id\"] == texas_musical_wikidata_id\n",
    "    df.loc[texas_musical_filter, \"Wikidata_id\"] = texas_state_wikidata_id\n",
    "    df.loc[texas_musical_filter, \"Wikidata_url\"] = f\"https://www.wikidata.org/wiki/Q{texas_state_wikidata_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_details_df(df: pd.DataFrame, doc_col: str):\n",
    "    copied_df = df.copy()\n",
    "    copied_df[\"entity\"] = copied_df[doc_col].apply(lambda doc: doc._.linkedEntities.entities)\n",
    "\n",
    "    entity_df = copied_df.explode(\"entity\").dropna()\n",
    "\n",
    "    # TODO: extract entity type\n",
    "    entity_details_df = pd.DataFrame(\n",
    "        data={\n",
    "            \"year\": entity_df[using_dataset[\"year_col\"]],\n",
    "            \"type\": entity_df[using_dataset[\"type_col\"]],\n",
    "            \"Entity\": entity_df[\"entity\"].apply(lambda ent: ent.get_label()),\n",
    "            \"Wikidata_id\": entity_df[\"entity\"].apply(lambda ent: ent.get_id()),\n",
    "            \"Wikidata_url\": entity_df[\"entity\"].apply(lambda ent: ent.get_url()),\n",
    "            \"Span\": entity_df[\"entity\"].apply(lambda ent: ent.get_span()),\n",
    "            \"Span_text\": entity_df[\"entity\"].apply(lambda ent: ent.get_span().text)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    clean_incorrect_president_entity(entity_details_df)\n",
    "    clean_incorrect_texas_entity(entity_details_df)\n",
    "\n",
    "    # If the entity label is missing, fill it in with the span text.\n",
    "    # This is rare, but sometimes happens\n",
    "    entity_details_df[\"Entity\"] = entity_details_df[\"Entity\"].fillna(entity_details_df[\"Span_text\"])\n",
    "\n",
    "    return entity_details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Wikidata_id</th>\n",
       "      <th>Wikidata_url</th>\n",
       "      <th>Span</th>\n",
       "      <th>Span_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>The Residents</td>\n",
       "      <td>947955</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q947955</td>\n",
       "      <td>(Residents)</td>\n",
       "      <td>Residents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>state</td>\n",
       "      <td>7275</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q7275</td>\n",
       "      <td>(states)</td>\n",
       "      <td>states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>pet</td>\n",
       "      <td>39201</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q39201</td>\n",
       "      <td>(pet)</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>humane society</td>\n",
       "      <td>1636604</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q1636604</td>\n",
       "      <td>(Humane, Society)</td>\n",
       "      <td>Humane Society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>compliance</td>\n",
       "      <td>633140</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q633140</td>\n",
       "      <td>(compliance)</td>\n",
       "      <td>compliance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year           type          Entity  Wikidata_id  \\\n",
       "0  2016  News and blog   The Residents       947955   \n",
       "0  2016  News and blog           state         7275   \n",
       "0  2016  News and blog             pet        39201   \n",
       "0  2016  News and blog  humane society      1636604   \n",
       "0  2016  News and blog      compliance       633140   \n",
       "\n",
       "                             Wikidata_url               Span       Span_text  \n",
       "0   https://www.wikidata.org/wiki/Q947955        (Residents)       Residents  \n",
       "0     https://www.wikidata.org/wiki/Q7275           (states)          states  \n",
       "0    https://www.wikidata.org/wiki/Q39201              (pet)             pet  \n",
       "0  https://www.wikidata.org/wiki/Q1636604  (Humane, Society)  Humane Society  \n",
       "0   https://www.wikidata.org/wiki/Q633140       (compliance)      compliance  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_entity_details_df = get_entity_details_df(dataset_df, \"text_doc\")\n",
    "text_entity_details_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Wikidata_id</th>\n",
       "      <th>Wikidata_url</th>\n",
       "      <th>Span</th>\n",
       "      <th>Span_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>State</td>\n",
       "      <td>16928008</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q16928008</td>\n",
       "      <td>(States)</td>\n",
       "      <td>States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>tool</td>\n",
       "      <td>39546</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q39546</td>\n",
       "      <td>(Implement)</td>\n",
       "      <td>Implement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Ordinance</td>\n",
       "      <td>25339629</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q25339629</td>\n",
       "      <td>(Ordinance)</td>\n",
       "      <td>Ordinance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Pet</td>\n",
       "      <td>22905746</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q22905746</td>\n",
       "      <td>(Pet)</td>\n",
       "      <td>Pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>Press release</td>\n",
       "      <td>theatrical property</td>\n",
       "      <td>942297</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q942297</td>\n",
       "      <td>(Prop)</td>\n",
       "      <td>Prop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year           type               Entity  Wikidata_id  \\\n",
       "0  2016  News and blog                State     16928008   \n",
       "0  2016  News and blog                 tool        39546   \n",
       "0  2016  News and blog            Ordinance     25339629   \n",
       "0  2016  News and blog                  Pet     22905746   \n",
       "1  2016  Press release  theatrical property       942297   \n",
       "\n",
       "                              Wikidata_url         Span  Span_text  \n",
       "0  https://www.wikidata.org/wiki/Q16928008     (States)     States  \n",
       "0     https://www.wikidata.org/wiki/Q39546  (Implement)  Implement  \n",
       "0  https://www.wikidata.org/wiki/Q25339629  (Ordinance)  Ordinance  \n",
       "0  https://www.wikidata.org/wiki/Q22905746        (Pet)        Pet  \n",
       "1    https://www.wikidata.org/wiki/Q942297       (Prop)       Prop  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_entity_details_df = get_entity_details_df(dataset_df, \"headline_doc\")\n",
    "headline_entity_details_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AH8Yysi3AllK"
   },
   "source": [
    "## Group dataframes by year and count named entities\n",
    "Currently, entityLinker catches all entities, not just proper nouns. To get around this, we first create dataframes filtering by year, then get the POS tags using spacy. This will then allow us to filter the dataframes further by excluding any counted nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XVTMgcPR7yx7"
   },
   "outputs": [],
   "source": [
    "def get_count(df: pd.DataFrame):\n",
    "  copied_df = df.copy()\n",
    "  copied_df['Count'] = copied_df.groupby(['Wikidata_id'])['Wikidata_id'].transform('count')\n",
    "  sorted_df = copied_df.sort_values(by=['Count'], ascending=False)\n",
    "  unique_df = sorted_df.drop_duplicates(subset=[\"Wikidata_id\"])\n",
    "\n",
    "  return unique_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "br0e4lxp12Sb"
   },
   "outputs": [],
   "source": [
    "tagger = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting entity counts and keeping only proper nouns to get rid of common regular words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_years_dfs(df: pd.DataFrame):\n",
    "    years, years_dfs = get_groups(df, \"year\")\n",
    "\n",
    "    year_counts_dfs = [get_count(df) for df in years_dfs]\n",
    "\n",
    "    for df in year_counts_dfs:\n",
    "        df['POS'] = [doc[0].pos_ for doc in tagger.pipe(df['Entity'])]\n",
    "    \n",
    "    propn_year_counts_dfs = [df[df[\"POS\"] == \"PROPN\"] for df in year_counts_dfs]\n",
    "\n",
    "    return years, propn_year_counts_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Wikidata_id</th>\n",
       "      <th>Wikidata_url</th>\n",
       "      <th>Span</th>\n",
       "      <th>Span_text</th>\n",
       "      <th>Count</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2007</td>\n",
       "      <td>Press release</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>1760704</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q1760704</td>\n",
       "      <td>(withdrawal)</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>2</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2007</td>\n",
       "      <td>Press release</td>\n",
       "      <td>Bill Clinton</td>\n",
       "      <td>1124</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q1124</td>\n",
       "      <td>(Clinton)</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>2</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2007</td>\n",
       "      <td>Press release</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>796</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q796</td>\n",
       "      <td>(Iraq)</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>2</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2007</td>\n",
       "      <td>Press release</td>\n",
       "      <td>Monday</td>\n",
       "      <td>105</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q105</td>\n",
       "      <td>(Monday)</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2007</td>\n",
       "      <td>Press release</td>\n",
       "      <td>Chance the Rapper</td>\n",
       "      <td>12470060</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q12470060</td>\n",
       "      <td>(chance)</td>\n",
       "      <td>chance</td>\n",
       "      <td>1</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year           type             Entity  Wikidata_id  \\\n",
       "428  2007  Press release         withdrawal      1760704   \n",
       "428  2007  Press release       Bill Clinton         1124   \n",
       "428  2007  Press release               Iraq          796   \n",
       "428  2007  Press release             Monday          105   \n",
       "428  2007  Press release  Chance the Rapper     12470060   \n",
       "\n",
       "                                Wikidata_url          Span   Span_text  Count  \\\n",
       "428   https://www.wikidata.org/wiki/Q1760704  (withdrawal)  withdrawal      2   \n",
       "428      https://www.wikidata.org/wiki/Q1124     (Clinton)     Clinton      2   \n",
       "428       https://www.wikidata.org/wiki/Q796        (Iraq)        Iraq      2   \n",
       "428       https://www.wikidata.org/wiki/Q105      (Monday)      Monday      1   \n",
       "428  https://www.wikidata.org/wiki/Q12470060      (chance)      chance      1   \n",
       "\n",
       "       POS  \n",
       "428  PROPN  \n",
       "428  PROPN  \n",
       "428  PROPN  \n",
       "428  PROPN  \n",
       "428  PROPN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_text, years_text_dfs = get_years_dfs(text_entity_details_df)\n",
    "years_text_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Wikidata_id</th>\n",
       "      <th>Wikidata_url</th>\n",
       "      <th>Span</th>\n",
       "      <th>Span_text</th>\n",
       "      <th>Count</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2007</td>\n",
       "      <td>Press release</td>\n",
       "      <td>John McCain</td>\n",
       "      <td>10390</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q10390</td>\n",
       "      <td>(John, McCain)</td>\n",
       "      <td>John McCain</td>\n",
       "      <td>1</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2007</td>\n",
       "      <td>Press release</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>6294</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q6294</td>\n",
       "      <td>(Hillary, Clinton)</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>1</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year           type           Entity  Wikidata_id  \\\n",
       "428  2007  Press release      John McCain        10390   \n",
       "428  2007  Press release  Hillary Clinton         6294   \n",
       "\n",
       "                             Wikidata_url                Span  \\\n",
       "428  https://www.wikidata.org/wiki/Q10390      (John, McCain)   \n",
       "428   https://www.wikidata.org/wiki/Q6294  (Hillary, Clinton)   \n",
       "\n",
       "           Span_text  Count    POS  \n",
       "428      John McCain      1  PROPN  \n",
       "428  Hillary Clinton      1  PROPN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_headline, years_headline_dfs = get_years_dfs(headline_entity_details_df)\n",
    "years_headline_dfs[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dx7K1TwSorck"
   },
   "source": [
    "## Write results to Excel spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_entity_counts_for_years(years: list[int], dfs: list[pd.DataFrame], output_path: str):\n",
    "    writer = pd.ExcelWriter(output_path, engine=\"xlsxwriter\")\n",
    "    \n",
    "    for year, df in zip(years, dfs):\n",
    "        df.to_excel(\n",
    "            writer,\n",
    "            sheet_name=str(year),\n",
    "            index=False,\n",
    "            columns=[\"Entity\", \"Wikidata_id\", \"Wikidata_url\", \"Span_text\", \"Count\"]\n",
    "        )\n",
    "    \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_entity_counts_for_years(\n",
    "    years=years_text, \n",
    "    dfs=years_text_dfs, \n",
    "    output_path=make_output_path(using_dataset, \"named_entities_frequency\")\n",
    ")\n",
    "\n",
    "save_entity_counts_for_years(\n",
    "    years=years_headline, \n",
    "    dfs=years_headline_dfs, \n",
    "    output_path=make_output_path(using_dataset, \"named_entities_frequency_headlines\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_entity_counts_for_types(entity_details_df: pd.DataFrame, suffix = \"\"):\n",
    "    types, types_dfs = get_groups(entity_details_df, \"type\")\n",
    "\n",
    "    for type, df in zip(types, types_dfs):\n",
    "        years_text, years_text_dfs = get_years_dfs(df)\n",
    "\n",
    "        save_entity_counts_for_years(\n",
    "            years=years_text, \n",
    "            dfs=years_text_dfs, \n",
    "            output_path=make_output_path_for_type(using_dataset, type, f\"named_entities_frequency{suffix}\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_entity_counts_for_types(text_entity_details_df)\n",
    "save_entity_counts_for_types(headline_entity_details_df, \"_headlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOPZdSsADjp2P11jYW7Zcpa",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
