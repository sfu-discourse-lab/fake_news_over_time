{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLPAMQpsoQhN"
   },
   "source": [
    "# Notebook for Named Entity Recognition\n",
    "\n",
    "Using spaCy for named entity recognition, we want to create relative frequency tables for the entities by year. At this point, we are only interested in the entities that appear most frequently.\n",
    "\n",
    "Currently processes the \"Fakespeak-ENG modified.xlsx\" file (I've renamed my copy to \"Fakespeak_ENG_modified.xlsx\" to create a more consistent path), but will eventually be run on data from MisInfoText as well.\n",
    "\n",
    "From the original data file, we use the following columns: ID, combinedLabel, originalTextType, originalBodyText, originalDateYear\n",
    "\n",
    "We are processing text from the \"originalBodyText\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QC2bXdxK2nxV"
   },
   "outputs": [],
   "source": [
    "!pip install \"spacy~=3.0.6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sr1ZDOEi3-Xb"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZSqg2PnnR0u"
   },
   "outputs": [],
   "source": [
    "!pip install spacy-entity-linker==1.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DIZ26YGcpqYO"
   },
   "outputs": [],
   "source": [
    "!python -m spacy_entity_linker \"download_knowledge_base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "or0rhDkgmaVI"
   },
   "outputs": [],
   "source": [
    "# Only run this code if you're loading from Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ko3T7YsrkxJM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Iterable\n",
    "from itertools import chain\n",
    "import spacy\n",
    "from spacy.tokens.doc import Doc\n",
    "from spacy_entity_linker.EntityElement import EntityElement\n",
    "import pandas as pd\n",
    "from dataset_config import BASE_FAKESPEAK_CONFIG, BASE_MISINFOTEXT_CONFIG\n",
    "from helpers import get_groups, make_output_path, make_output_path_for_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-SwD9Clo1Lz"
   },
   "source": [
    "## Loading the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakespeak_config = BASE_FAKESPEAK_CONFIG | {\n",
    "    \"headline_col\": \"originalHeadline\",\n",
    "    \"usecols\": BASE_FAKESPEAK_CONFIG[\"usecols\"] + [\"originalHeadline\"]\n",
    "}\n",
    "\n",
    "misinfotext_config = BASE_MISINFOTEXT_CONFIG | {\n",
    "    \"headline_col\": \"originalHeadline\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_dataset = misinfotext_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rVQAdSteo7QM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factcheckURL</th>\n",
       "      <th>originalURL</th>\n",
       "      <th>originalBodyText</th>\n",
       "      <th>originalHeadline</th>\n",
       "      <th>originalTextType</th>\n",
       "      <th>originalDate</th>\n",
       "      <th>originalDateYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.politifact.com/arizona/statements/2...</td>\n",
       "      <td>https://associatedmediacoverage.com/three-stat...</td>\n",
       "      <td>Residents of multiple states will be asked to ...</td>\n",
       "      <td>Multiple States Have Agreed To Implement A ‘Tw...</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>2016-05-06</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>https://users.focalbeam.com/fs/distribution:wl...</td>\n",
       "      <td>Sacramento, CA - United States Senator Dianne ...</td>\n",
       "      <td>U.S. Senator Dianne Feinstein Opposes Prop. 64...</td>\n",
       "      <td>Press release</td>\n",
       "      <td>2016-07-12</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>http://www.sacbee.com/opinion/op-ed/soapbox/ar...</td>\n",
       "      <td>We should anticipate black and gray markets in...</td>\n",
       "      <td>Why you should buy a locking gasoline cap</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>https://nocagastax.com/california-gas-tax-hike...</td>\n",
       "      <td>As a ballot initiative calling for repeal of a...</td>\n",
       "      <td>California Gas-Tax-Hike Repeal Campaign Heats Up</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>2017-06-15</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>https://chu.house.gov/media-center/press-relea...</td>\n",
       "      <td>WASHINGTON, DC  The House of Representatives t...</td>\n",
       "      <td>Rep. Chu Decries \"Heartless\" ACA Repeal Vote</td>\n",
       "      <td>Press release</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        factcheckURL  \\\n",
       "0  http://www.politifact.com/arizona/statements/2...   \n",
       "1  http://www.politifact.com/california/statement...   \n",
       "2  http://www.politifact.com/california/statement...   \n",
       "3  http://www.politifact.com/california/statement...   \n",
       "4  http://www.politifact.com/california/statement...   \n",
       "\n",
       "                                         originalURL  \\\n",
       "0  https://associatedmediacoverage.com/three-stat...   \n",
       "1  https://users.focalbeam.com/fs/distribution:wl...   \n",
       "2  http://www.sacbee.com/opinion/op-ed/soapbox/ar...   \n",
       "3  https://nocagastax.com/california-gas-tax-hike...   \n",
       "4  https://chu.house.gov/media-center/press-relea...   \n",
       "\n",
       "                                    originalBodyText  \\\n",
       "0  Residents of multiple states will be asked to ...   \n",
       "1  Sacramento, CA - United States Senator Dianne ...   \n",
       "2  We should anticipate black and gray markets in...   \n",
       "3  As a ballot initiative calling for repeal of a...   \n",
       "4  WASHINGTON, DC  The House of Representatives t...   \n",
       "\n",
       "                                    originalHeadline originalTextType  \\\n",
       "0  Multiple States Have Agreed To Implement A ‘Tw...    News and blog   \n",
       "1  U.S. Senator Dianne Feinstein Opposes Prop. 64...    Press release   \n",
       "2          Why you should buy a locking gasoline cap    News and blog   \n",
       "3   California Gas-Tax-Hike Repeal Campaign Heats Up    News and blog   \n",
       "4       Rep. Chu Decries \"Heartless\" ACA Repeal Vote    Press release   \n",
       "\n",
       "  originalDate  originalDateYear  \n",
       "0   2016-05-06              2016  \n",
       "1   2016-07-12              2016  \n",
       "2   2017-08-04              2017  \n",
       "3   2017-06-15              2017  \n",
       "4   2017-05-04              2017  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = pd.read_excel(\n",
    "    using_dataset[\"input_path\"], \n",
    "    sheet_name=using_dataset[\"sheet_name\"], \n",
    "    usecols=using_dataset[\"usecols\"]\n",
    ")\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJCyzIzTpCJ5"
   },
   "source": [
    "## Tagging named entities using spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNLzISEbA9PG"
   },
   "source": [
    "To make up for the difficulties of consolidating similar named entities, we use spaCy's large web model to ensure higher tagging accuracy in the initial NER step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEYaN28SF_L3"
   },
   "source": [
    "Documentation for entityLinker: https://github.com/egerber/spaCy-entity-linker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YAbwHHn-jAjs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adam\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\site-packages\\coreferee\\manager.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "# load spacy model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# add custom entityLinker pipeline\n",
    "entity_linker = nlp.add_pipe(\"entityLinker\", last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factcheckURL</th>\n",
       "      <th>originalURL</th>\n",
       "      <th>originalBodyText</th>\n",
       "      <th>originalHeadline</th>\n",
       "      <th>originalTextType</th>\n",
       "      <th>originalDate</th>\n",
       "      <th>originalDateYear</th>\n",
       "      <th>text_doc</th>\n",
       "      <th>headline_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.politifact.com/arizona/statements/2...</td>\n",
       "      <td>https://associatedmediacoverage.com/three-stat...</td>\n",
       "      <td>Residents of multiple states will be asked to ...</td>\n",
       "      <td>Multiple States Have Agreed To Implement A ‘Tw...</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>2016-05-06</td>\n",
       "      <td>2016</td>\n",
       "      <td>(Residents, of, multiple, states, will, be, as...</td>\n",
       "      <td>(Multiple, States, Have, Agreed, To, Implement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>https://users.focalbeam.com/fs/distribution:wl...</td>\n",
       "      <td>Sacramento, CA - United States Senator Dianne ...</td>\n",
       "      <td>U.S. Senator Dianne Feinstein Opposes Prop. 64...</td>\n",
       "      <td>Press release</td>\n",
       "      <td>2016-07-12</td>\n",
       "      <td>2016</td>\n",
       "      <td>(Sacramento, ,, CA, -, United, States, Senator...</td>\n",
       "      <td>(U.S., Senator, Dianne, Feinstein, Opposes, Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>http://www.sacbee.com/opinion/op-ed/soapbox/ar...</td>\n",
       "      <td>We should anticipate black and gray markets in...</td>\n",
       "      <td>Why you should buy a locking gasoline cap</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>2017</td>\n",
       "      <td>(We, should, anticipate, black, and, gray, mar...</td>\n",
       "      <td>(Why, you, should, buy, a, locking, gasoline, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>https://nocagastax.com/california-gas-tax-hike...</td>\n",
       "      <td>As a ballot initiative calling for repeal of a...</td>\n",
       "      <td>California Gas-Tax-Hike Repeal Campaign Heats Up</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>2017-06-15</td>\n",
       "      <td>2017</td>\n",
       "      <td>(As, a, ballot, initiative, calling, for, repe...</td>\n",
       "      <td>(California, Gas, -, Tax, -, Hike, Repeal, Cam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.politifact.com/california/statement...</td>\n",
       "      <td>https://chu.house.gov/media-center/press-relea...</td>\n",
       "      <td>WASHINGTON, DC  The House of Representatives t...</td>\n",
       "      <td>Rep. Chu Decries \"Heartless\" ACA Repeal Vote</td>\n",
       "      <td>Press release</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>2017</td>\n",
       "      <td>(WASHINGTON, ,, DC,  , The, House, of, Represe...</td>\n",
       "      <td>(Rep., Chu, Decries, \", Heartless, \", ACA, Rep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        factcheckURL  \\\n",
       "0  http://www.politifact.com/arizona/statements/2...   \n",
       "1  http://www.politifact.com/california/statement...   \n",
       "2  http://www.politifact.com/california/statement...   \n",
       "3  http://www.politifact.com/california/statement...   \n",
       "4  http://www.politifact.com/california/statement...   \n",
       "\n",
       "                                         originalURL  \\\n",
       "0  https://associatedmediacoverage.com/three-stat...   \n",
       "1  https://users.focalbeam.com/fs/distribution:wl...   \n",
       "2  http://www.sacbee.com/opinion/op-ed/soapbox/ar...   \n",
       "3  https://nocagastax.com/california-gas-tax-hike...   \n",
       "4  https://chu.house.gov/media-center/press-relea...   \n",
       "\n",
       "                                    originalBodyText  \\\n",
       "0  Residents of multiple states will be asked to ...   \n",
       "1  Sacramento, CA - United States Senator Dianne ...   \n",
       "2  We should anticipate black and gray markets in...   \n",
       "3  As a ballot initiative calling for repeal of a...   \n",
       "4  WASHINGTON, DC  The House of Representatives t...   \n",
       "\n",
       "                                    originalHeadline originalTextType  \\\n",
       "0  Multiple States Have Agreed To Implement A ‘Tw...    News and blog   \n",
       "1  U.S. Senator Dianne Feinstein Opposes Prop. 64...    Press release   \n",
       "2          Why you should buy a locking gasoline cap    News and blog   \n",
       "3   California Gas-Tax-Hike Repeal Campaign Heats Up    News and blog   \n",
       "4       Rep. Chu Decries \"Heartless\" ACA Repeal Vote    Press release   \n",
       "\n",
       "  originalDate  originalDateYear  \\\n",
       "0   2016-05-06              2016   \n",
       "1   2016-07-12              2016   \n",
       "2   2017-08-04              2017   \n",
       "3   2017-06-15              2017   \n",
       "4   2017-05-04              2017   \n",
       "\n",
       "                                            text_doc  \\\n",
       "0  (Residents, of, multiple, states, will, be, as...   \n",
       "1  (Sacramento, ,, CA, -, United, States, Senator...   \n",
       "2  (We, should, anticipate, black, and, gray, mar...   \n",
       "3  (As, a, ballot, initiative, calling, for, repe...   \n",
       "4  (WASHINGTON, ,, DC,  , The, House, of, Represe...   \n",
       "\n",
       "                                        headline_doc  \n",
       "0  (Multiple, States, Have, Agreed, To, Implement...  \n",
       "1  (U.S., Senator, Dianne, Feinstein, Opposes, Pr...  \n",
       "2  (Why, you, should, buy, a, locking, gasoline, ...  \n",
       "3  (California, Gas, -, Tax, -, Hike, Repeal, Cam...  \n",
       "4  (Rep., Chu, Decries, \", Heartless, \", ACA, Rep...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[\"text_doc\"] = list(nlp.pipe(dataset_df[using_dataset[\"text_col\"]]))\n",
    "dataset_df[\"headline_doc\"] = list(nlp.pipe(dataset_df[using_dataset[\"headline_col\"]].fillna(\"\")))\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reason, any spans of just \"President\" (or similar)\n",
    "# get tagged as Zhong Chenle, maybe because he has an alias \"President\".\n",
    "# The following code fixes that to point to the correct Wikidata entry\n",
    "# for the generic term \"president\".\n",
    "\n",
    "zhong_chenle_president_aliases = {'PRESIDENT', 'President', 'Presidents'}\n",
    "zhong_chenle_wikidata_id = 30945670\n",
    "president_wikidata_id = 30461\n",
    "\n",
    "def clean_incorrect_president_entity(df: pd.DataFrame):\n",
    "    zhong_chenle_as_president_filter = (df[\"Wikidata_id\"] == zhong_chenle_wikidata_id) & (df[\"Span_text\"].isin(zhong_chenle_president_aliases))\n",
    "    df.loc[zhong_chenle_as_president_filter, \"Entity\"] = \"president\"\n",
    "    df.loc[zhong_chenle_as_president_filter, \"Wikidata_id\"] = president_wikidata_id\n",
    "    df.loc[zhong_chenle_as_president_filter, \"Wikidata_url\"] = f\"https://www.wikidata.org/wiki/Q{president_wikidata_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A similar thing is happening where the state of Texas\n",
    "# is sometimes confused for a musical play named \"Texas\". \n",
    "\n",
    "texas_musical_wikidata_id = 7707415\n",
    "texas_state_wikidata_id = 1439\n",
    "\n",
    "def clean_incorrect_texas_entity(df: pd.DataFrame):\n",
    "    texas_musical_filter = df[\"Wikidata_id\"] == texas_musical_wikidata_id\n",
    "    df.loc[texas_musical_filter, \"Wikidata_id\"] = texas_state_wikidata_id\n",
    "    df.loc[texas_musical_filter, \"Wikidata_url\"] = f\"https://www.wikidata.org/wiki/Q{texas_state_wikidata_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Wikidata_id</th>\n",
       "      <th>Wikidata_url</th>\n",
       "      <th>Span_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>The Residents</td>\n",
       "      <td>947955</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q947955</td>\n",
       "      <td>Residents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>state</td>\n",
       "      <td>7275</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q7275</td>\n",
       "      <td>states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>pet</td>\n",
       "      <td>39201</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q39201</td>\n",
       "      <td>pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>humane society</td>\n",
       "      <td>1636604</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q1636604</td>\n",
       "      <td>Humane Society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>compliance</td>\n",
       "      <td>633140</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q633140</td>\n",
       "      <td>compliance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year           type          Entity  Wikidata_id  \\\n",
       "0  2016  News and blog   The Residents       947955   \n",
       "0  2016  News and blog           state         7275   \n",
       "0  2016  News and blog             pet        39201   \n",
       "0  2016  News and blog  humane society      1636604   \n",
       "0  2016  News and blog      compliance       633140   \n",
       "\n",
       "                             Wikidata_url       Span_text  \n",
       "0   https://www.wikidata.org/wiki/Q947955       Residents  \n",
       "0     https://www.wikidata.org/wiki/Q7275          states  \n",
       "0    https://www.wikidata.org/wiki/Q39201             pet  \n",
       "0  https://www.wikidata.org/wiki/Q1636604  Humane Society  \n",
       "0   https://www.wikidata.org/wiki/Q633140      compliance  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[\"text_entities\"] = dataset_df[\"text_doc\"].apply(lambda doc: doc._.linkedEntities.entities)\n",
    "text_entities_df = dataset_df.explode(\"text_entities\")\n",
    "\n",
    "# TODO: extract entity type\n",
    "\n",
    "text_entities_data_df = pd.DataFrame(\n",
    "    data={\n",
    "        \"year\": text_entities_df[using_dataset[\"year_col\"]],\n",
    "        \"type\": text_entities_df[using_dataset[\"type_col\"]],\n",
    "        \"Entity\": text_entities_df[\"text_entities\"].apply(lambda ent: ent.get_label()),\n",
    "        \"Wikidata_id\": text_entities_df[\"text_entities\"].apply(lambda ent: ent.get_id()),\n",
    "        \"Wikidata_url\": text_entities_df[\"text_entities\"].apply(lambda ent: ent.get_url()),\n",
    "        \"Span_text\": text_entities_df[\"text_entities\"].apply(lambda ent: ent.get_span().text)\n",
    "    }\n",
    ")\n",
    "\n",
    "clean_incorrect_president_entity(text_entities_data_df)\n",
    "clean_incorrect_texas_entity(text_entities_data_df)\n",
    "\n",
    "text_entities_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Wikidata_id</th>\n",
       "      <th>Wikidata_url</th>\n",
       "      <th>Span_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>State</td>\n",
       "      <td>16928008</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q16928008</td>\n",
       "      <td>States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>tool</td>\n",
       "      <td>39546</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q39546</td>\n",
       "      <td>Implement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Ordinance</td>\n",
       "      <td>25339629</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q25339629</td>\n",
       "      <td>Ordinance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Pet</td>\n",
       "      <td>22905746</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q22905746</td>\n",
       "      <td>Pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>Press release</td>\n",
       "      <td>theatrical property</td>\n",
       "      <td>942297</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q942297</td>\n",
       "      <td>Prop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year           type               Entity  Wikidata_id  \\\n",
       "0  2016  News and blog                State     16928008   \n",
       "0  2016  News and blog                 tool        39546   \n",
       "0  2016  News and blog            Ordinance     25339629   \n",
       "0  2016  News and blog                  Pet     22905746   \n",
       "1  2016  Press release  theatrical property       942297   \n",
       "\n",
       "                              Wikidata_url  Span_text  \n",
       "0  https://www.wikidata.org/wiki/Q16928008     States  \n",
       "0     https://www.wikidata.org/wiki/Q39546  Implement  \n",
       "0  https://www.wikidata.org/wiki/Q25339629  Ordinance  \n",
       "0  https://www.wikidata.org/wiki/Q22905746        Pet  \n",
       "1    https://www.wikidata.org/wiki/Q942297       Prop  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[\"headline_entities\"] = dataset_df[\"headline_doc\"].apply(lambda doc: doc._.linkedEntities.entities)\n",
    "headline_entities_df = dataset_df.explode(\"headline_entities\")\n",
    "headline_entities_df = headline_entities_df[headline_entities_df[\"headline_entities\"].notnull()]\n",
    "\n",
    "# TODO: extract entity type\n",
    "\n",
    "headline_entities_data_df = pd.DataFrame(\n",
    "    data={\n",
    "        \"year\": headline_entities_df[using_dataset[\"year_col\"]],\n",
    "        \"type\": headline_entities_df[using_dataset[\"type_col\"]],\n",
    "        \"Entity\": headline_entities_df[\"headline_entities\"].apply(lambda ent: ent.get_label()),\n",
    "        \"Wikidata_id\": headline_entities_df[\"headline_entities\"].apply(lambda ent: ent.get_id()),\n",
    "        \"Wikidata_url\": headline_entities_df[\"headline_entities\"].apply(lambda ent: ent.get_url()),\n",
    "        \"Span_text\": headline_entities_df[\"headline_entities\"].apply(lambda ent: ent.get_span().text)\n",
    "    }\n",
    ")\n",
    "\n",
    "clean_incorrect_president_entity(headline_entities_data_df)\n",
    "clean_incorrect_texas_entity(headline_entities_data_df)\n",
    "\n",
    "headline_entities_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AH8Yysi3AllK"
   },
   "source": [
    "## Group dataframes by year and named entities\n",
    "Currently, entityLinker catches all entities, not just proper nouns. To get around this, we first create dataframes filtering by year, then get the POS tags using spacy. This will then allow us to filter the dataframes further by excluding any counted nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XVTMgcPR7yx7"
   },
   "outputs": [],
   "source": [
    "def get_count(df: pd.DataFrame):\n",
    "  copied_df = df.copy()\n",
    "  copied_df['Count'] = copied_df.groupby(['Wikidata_id'])['Wikidata_id'].transform('count')\n",
    "  sorted_df = copied_df.sort_values(by=['Count'], ascending=False)\n",
    "  unique_df = sorted_df.drop_duplicates(subset=[\"Wikidata_id\"])\n",
    "\n",
    "  return unique_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "br0e4lxp12Sb"
   },
   "outputs": [],
   "source": [
    "tagger = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting entity counts and keeping only proper nouns to get rid of common regular words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Wikidata_id</th>\n",
       "      <th>Wikidata_url</th>\n",
       "      <th>Span_text</th>\n",
       "      <th>Count</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2007</td>\n",
       "      <td>Press release</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>1760704</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q1760704</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>2</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2007</td>\n",
       "      <td>Press release</td>\n",
       "      <td>Bill Clinton</td>\n",
       "      <td>1124</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q1124</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>2</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2007</td>\n",
       "      <td>Press release</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>796</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q796</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>2</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2007</td>\n",
       "      <td>Press release</td>\n",
       "      <td>Monday</td>\n",
       "      <td>105</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q105</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2007</td>\n",
       "      <td>Press release</td>\n",
       "      <td>Chance the Rapper</td>\n",
       "      <td>12470060</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q12470060</td>\n",
       "      <td>chance</td>\n",
       "      <td>1</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year           type             Entity  Wikidata_id  \\\n",
       "428  2007  Press release         withdrawal      1760704   \n",
       "428  2007  Press release       Bill Clinton         1124   \n",
       "428  2007  Press release               Iraq          796   \n",
       "428  2007  Press release             Monday          105   \n",
       "428  2007  Press release  Chance the Rapper     12470060   \n",
       "\n",
       "                                Wikidata_url   Span_text  Count    POS  \n",
       "428   https://www.wikidata.org/wiki/Q1760704  withdrawal      2  PROPN  \n",
       "428      https://www.wikidata.org/wiki/Q1124     Clinton      2  PROPN  \n",
       "428       https://www.wikidata.org/wiki/Q796        Iraq      2  PROPN  \n",
       "428       https://www.wikidata.org/wiki/Q105      Monday      1  PROPN  \n",
       "428  https://www.wikidata.org/wiki/Q12470060      chance      1  PROPN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_text, years_text_dfs = get_groups(text_entities_data_df, \"year\")\n",
    "\n",
    "years_text_count_dfs = [get_count(df) for df in years_text_dfs]\n",
    "\n",
    "for df in years_text_count_dfs:\n",
    "    df['POS'] = [doc[0].pos_ for doc in tagger.pipe(df['Entity'].fillna(df[\"Span_text\"]))]\n",
    "\n",
    "filtered_years_text_count_dfs = [df[df[\"POS\"] == \"PROPN\"].copy() for df in years_text_count_dfs]\n",
    "\n",
    "filtered_years_text_count_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Wikidata_id</th>\n",
       "      <th>Wikidata_url</th>\n",
       "      <th>Span_text</th>\n",
       "      <th>Count</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2007</td>\n",
       "      <td>Press release</td>\n",
       "      <td>John McCain</td>\n",
       "      <td>10390</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q10390</td>\n",
       "      <td>John McCain</td>\n",
       "      <td>1</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2007</td>\n",
       "      <td>Press release</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>6294</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q6294</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>1</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year           type           Entity  Wikidata_id  \\\n",
       "428  2007  Press release      John McCain        10390   \n",
       "428  2007  Press release  Hillary Clinton         6294   \n",
       "\n",
       "                             Wikidata_url        Span_text  Count    POS  \n",
       "428  https://www.wikidata.org/wiki/Q10390      John McCain      1  PROPN  \n",
       "428   https://www.wikidata.org/wiki/Q6294  Hillary Clinton      1  PROPN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_headline, years_headline_dfs = get_groups(headline_entities_data_df, \"year\")\n",
    "\n",
    "years_headline_count_dfs = [get_count(df) for df in years_headline_dfs]\n",
    "\n",
    "for df in years_headline_count_dfs:\n",
    "    df['POS'] = [doc[0].pos_ for doc in tagger.pipe(df['Entity'].fillna(df[\"Span_text\"]))]\n",
    "\n",
    "filtered_years_headline_count_dfs = [df[df[\"POS\"] == \"PROPN\"].copy() for df in years_headline_count_dfs]\n",
    "\n",
    "filtered_years_headline_count_dfs[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dx7K1TwSorck"
   },
   "source": [
    "## Write results to Excel spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = make_output_path(using_dataset, \"named_entities_frequency\")\n",
    "\n",
    "writer = pd.ExcelWriter(output_path, engine=\"xlsxwriter\")\n",
    "\n",
    "for year, df in zip(years_text, filtered_years_text_count_dfs):\n",
    "    df.to_excel(\n",
    "        writer,\n",
    "        sheet_name=str(year),\n",
    "        index=False,\n",
    "        columns=[\"Entity\", \"Wikidata_id\", \"Wikidata_url\", \"Span_text\", \"Count\"]\n",
    "    )\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = make_output_path(using_dataset, \"named_entities_frequency_headlines\")\n",
    "\n",
    "writer = pd.ExcelWriter(output_path, engine=\"xlsxwriter\")\n",
    "\n",
    "for year, df in zip(years_headline, filtered_years_headline_count_dfs):\n",
    "    df.to_excel(\n",
    "        writer,\n",
    "        sheet_name=str(year),\n",
    "        index=False,\n",
    "        columns=[\"Entity\", \"Wikidata_id\", \"Wikidata_url\", \"Span_text\", \"Count\"]\n",
    "    )\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: consolidate all of the above to a function and then also run it on each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOPZdSsADjp2P11jYW7Zcpa",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
