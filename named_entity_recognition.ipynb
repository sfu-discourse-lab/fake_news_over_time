{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLPAMQpsoQhN"
   },
   "source": [
    "# Notebook for Named Entity Recognition\n",
    "\n",
    "Using spaCy for named entity recognition, we want to create relative frequency tables for the entities by year. At this point, we are only interested in the entities that appear most frequently.\n",
    "\n",
    "Currently processes the \"Fakespeak-ENG modified.xlsx\" file (I've renamed my copy to \"Fakespeak_ENG_modified.xlsx\" to create a more consistent path), but will eventually be run on data from MisInfoText as well.\n",
    "\n",
    "From the original data file, we use the following columns: ID, combinedLabel, originalTextType, originalBodyText, originalDateYear\n",
    "\n",
    "We are processing text from the \"originalBodyText\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QC2bXdxK2nxV"
   },
   "outputs": [],
   "source": [
    "!pip install \"spacy~=3.0.6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sr1ZDOEi3-Xb"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZSqg2PnnR0u"
   },
   "outputs": [],
   "source": [
    "!pip install spacy-entity-linker==1.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DIZ26YGcpqYO"
   },
   "outputs": [],
   "source": [
    "!python -m spacy_entity_linker \"download_knowledge_base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "or0rhDkgmaVI"
   },
   "outputs": [],
   "source": [
    "# Only run this code if you're loading from Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ko3T7YsrkxJM"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy.tokens.span import Span\n",
    "from spacy.tokens.doc import Doc\n",
    "from spacy_entity_linker.EntityElement import EntityElement\n",
    "from dataset_config import BASE_FAKESPEAK_CONFIG, BASE_MISINFOTEXT_CONFIG\n",
    "from helpers import get_groups, make_output_path, make_output_path_for_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-SwD9Clo1Lz"
   },
   "source": [
    "## Loading the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakespeak_config = BASE_FAKESPEAK_CONFIG | {\n",
    "    \"headline_col\": \"originalHeadline\",\n",
    "    \"usecols\": BASE_FAKESPEAK_CONFIG[\"usecols\"] + [\"originalHeadline\"]\n",
    "}\n",
    "\n",
    "misinfotext_config = BASE_MISINFOTEXT_CONFIG | {\n",
    "    \"headline_col\": \"originalHeadline\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_dataset = fakespeak_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rVQAdSteo7QM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>combinedLabel</th>\n",
       "      <th>originalTextType</th>\n",
       "      <th>originalBodyText</th>\n",
       "      <th>originalHeadline</th>\n",
       "      <th>originalDateYear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Politifact_FALSE_Social media_687276</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Mexico is paying for the Wall through the new ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Politifact_FALSE_Social media_25111</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Chuck Schumer: \"why should American citizens b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Politifact_FALSE_Social media_735424</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Billions of dollars are sent to the State of C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Politifact_FALSE_Social media_594307</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>If 50 Billion $$ were set aside to go towards ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Politifact_FALSE_Social media_839325</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Huge@#CD 9 news. \\n@ncsbe\\n sent letter to eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID combinedLabel originalTextType  \\\n",
       "0  Politifact_FALSE_Social media_687276         False     Social media   \n",
       "1   Politifact_FALSE_Social media_25111         False     Social media   \n",
       "2  Politifact_FALSE_Social media_735424         False     Social media   \n",
       "3  Politifact_FALSE_Social media_594307         False     Social media   \n",
       "4  Politifact_FALSE_Social media_839325         False     Social media   \n",
       "\n",
       "                                    originalBodyText originalHeadline  \\\n",
       "0  Mexico is paying for the Wall through the new ...              NaN   \n",
       "1  Chuck Schumer: \"why should American citizens b...              NaN   \n",
       "2  Billions of dollars are sent to the State of C...              NaN   \n",
       "3  If 50 Billion $$ were set aside to go towards ...              NaN   \n",
       "4  Huge@#CD 9 news. \\n@ncsbe\\n sent letter to eve...              NaN   \n",
       "\n",
       "   originalDateYear  \n",
       "0              2019  \n",
       "1              2019  \n",
       "2              2019  \n",
       "3              2019  \n",
       "4              2019  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = pd.read_excel(\n",
    "    using_dataset[\"input_path\"], \n",
    "    sheet_name=using_dataset[\"sheet_name\"], \n",
    "    usecols=using_dataset[\"usecols\"]\n",
    ")\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJCyzIzTpCJ5"
   },
   "source": [
    "## Tagging named entities using spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNLzISEbA9PG"
   },
   "source": [
    "To make up for the difficulties of consolidating similar named entities, we use spaCy's large web model to ensure higher tagging accuracy in the initial NER step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEYaN28SF_L3"
   },
   "source": [
    "Documentation for entityLinker: https://github.com/egerber/spaCy-entity-linker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YAbwHHn-jAjs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adam\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\site-packages\\coreferee\\manager.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "# load spacy model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# add custom entityLinker pipeline\n",
    "entity_linker = nlp.add_pipe(\"entityLinker\", last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>combinedLabel</th>\n",
       "      <th>originalTextType</th>\n",
       "      <th>originalBodyText</th>\n",
       "      <th>originalHeadline</th>\n",
       "      <th>originalDateYear</th>\n",
       "      <th>text_doc</th>\n",
       "      <th>headline_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Politifact_FALSE_Social media_687276</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Mexico is paying for the Wall through the new ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>(Mexico, is, paying, for, the, Wall, through, ...</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Politifact_FALSE_Social media_25111</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Chuck Schumer: \"why should American citizens b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>(Chuck, Schumer, :, \", why, should, American, ...</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Politifact_FALSE_Social media_735424</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Billions of dollars are sent to the State of C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>(Billions, of, dollars, are, sent, to, the, St...</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Politifact_FALSE_Social media_594307</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>If 50 Billion $$ were set aside to go towards ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>(If, 50, Billion, $, $, were, set, aside, to, ...</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Politifact_FALSE_Social media_839325</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Huge@#CD 9 news. \\n@ncsbe\\n sent letter to eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>(Huge@#CD, 9, news, ., \\n, @ncsbe, \\n , sent, ...</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID combinedLabel originalTextType  \\\n",
       "0  Politifact_FALSE_Social media_687276         False     Social media   \n",
       "1   Politifact_FALSE_Social media_25111         False     Social media   \n",
       "2  Politifact_FALSE_Social media_735424         False     Social media   \n",
       "3  Politifact_FALSE_Social media_594307         False     Social media   \n",
       "4  Politifact_FALSE_Social media_839325         False     Social media   \n",
       "\n",
       "                                    originalBodyText originalHeadline  \\\n",
       "0  Mexico is paying for the Wall through the new ...              NaN   \n",
       "1  Chuck Schumer: \"why should American citizens b...              NaN   \n",
       "2  Billions of dollars are sent to the State of C...              NaN   \n",
       "3  If 50 Billion $$ were set aside to go towards ...              NaN   \n",
       "4  Huge@#CD 9 news. \\n@ncsbe\\n sent letter to eve...              NaN   \n",
       "\n",
       "   originalDateYear                                           text_doc  \\\n",
       "0              2019  (Mexico, is, paying, for, the, Wall, through, ...   \n",
       "1              2019  (Chuck, Schumer, :, \", why, should, American, ...   \n",
       "2              2019  (Billions, of, dollars, are, sent, to, the, St...   \n",
       "3              2019  (If, 50, Billion, $, $, were, set, aside, to, ...   \n",
       "4              2019  (Huge@#CD, 9, news, ., \\n, @ncsbe, \\n , sent, ...   \n",
       "\n",
       "  headline_doc  \n",
       "0           ()  \n",
       "1           ()  \n",
       "2           ()  \n",
       "3           ()  \n",
       "4           ()  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[\"text_doc\"] = list(nlp.pipe(dataset_df[using_dataset[\"text_col\"]]))\n",
    "dataset_df[\"headline_doc\"] = list(nlp.pipe(dataset_df[using_dataset[\"headline_col\"]].fillna(\"\")))\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reason, any spans of just \"President\" (or similar)\n",
    "# get tagged as Zhong Chenle, maybe because he has an alias \"President\".\n",
    "# The following code fixes that to point to the correct Wikidata entry\n",
    "# for the generic term \"president\".\n",
    "\n",
    "zhong_chenle_president_aliases = {'PRESIDENT', 'President', 'Presidents'}\n",
    "zhong_chenle_wikidata_id = 30945670\n",
    "president_wikidata_id = 30461\n",
    "\n",
    "def clean_incorrect_president_entity(df: pd.DataFrame):\n",
    "    zhong_chenle_as_president_filter = (df[\"Wikidata_id\"] == zhong_chenle_wikidata_id) & (df[\"Span_text\"].isin(zhong_chenle_president_aliases))\n",
    "    df.loc[zhong_chenle_as_president_filter, \"Entity\"] = \"president\"\n",
    "    df.loc[zhong_chenle_as_president_filter, \"Wikidata_id\"] = president_wikidata_id\n",
    "    df.loc[zhong_chenle_as_president_filter, \"Wikidata_url\"] = f\"https://www.wikidata.org/wiki/Q{president_wikidata_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A similar thing is happening where the state of Texas\n",
    "# is sometimes confused for a musical play named \"Texas\". \n",
    "\n",
    "texas_musical_wikidata_id = 7707415\n",
    "texas_state_wikidata_id = 1439\n",
    "\n",
    "def clean_incorrect_texas_entity(df: pd.DataFrame):\n",
    "    texas_musical_filter = df[\"Wikidata_id\"] == texas_musical_wikidata_id\n",
    "    df.loc[texas_musical_filter, \"Wikidata_id\"] = texas_state_wikidata_id\n",
    "    df.loc[texas_musical_filter, \"Wikidata_url\"] = f\"https://www.wikidata.org/wiki/Q{texas_state_wikidata_id}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spacy_entity_linker package doesn't include NER tags like PERSON, ORG, GPE, etc. So to extract them, we have to try to match the linked entities to the original spacy entities, and grab the NER tag from those. This doesn't always work because the entities don't always line up. But in the final output, most proper noun entities end up having a tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_tag(row: pd.Series, doc_col: str):\n",
    "    linked_entity: EntityElement = row[\"entity\"]\n",
    "    linked_entity_span: Span = linked_entity.get_span()\n",
    "\n",
    "    doc: Doc = row[doc_col]\n",
    "\n",
    "    for entity in doc.ents:\n",
    "        if linked_entity_span.start >= entity.start and linked_entity_span.end <= entity.end:\n",
    "            return entity.label_\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_details_df(df: pd.DataFrame, doc_col: str):\n",
    "    copied_df = df.copy()\n",
    "    copied_df[\"entity\"] = copied_df[doc_col].apply(lambda doc: doc._.linkedEntities.entities)\n",
    "\n",
    "    entity_df = copied_df.explode(\"entity\").dropna()\n",
    "    entity_df[\"tag\"] = entity_df.apply(get_entity_tag, args=(doc_col,), axis=1)\n",
    "\n",
    "    entity_details_df = pd.DataFrame(\n",
    "        data={\n",
    "            \"year\": entity_df[using_dataset[\"year_col\"]],\n",
    "            \"type\": entity_df[using_dataset[\"type_col\"]],\n",
    "            \"Entity\": entity_df[\"entity\"].apply(lambda ent: ent.get_label()),\n",
    "            \"tag\": entity_df[\"tag\"],\n",
    "            \"Wikidata_id\": entity_df[\"entity\"].apply(lambda ent: ent.get_id()),\n",
    "            \"Wikidata_url\": entity_df[\"entity\"].apply(lambda ent: ent.get_url()),\n",
    "            \"Span\": entity_df[\"entity\"].apply(lambda ent: ent.get_span()),\n",
    "            \"Span_text\": entity_df[\"entity\"].apply(lambda ent: ent.get_span().text)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    clean_incorrect_president_entity(entity_details_df)\n",
    "    clean_incorrect_texas_entity(entity_details_df)\n",
    "\n",
    "    # If the entity label is missing, fill it in with the span text.\n",
    "    # This is rare, but sometimes happens\n",
    "    entity_details_df[\"Entity\"] = entity_details_df[\"Entity\"].fillna(entity_details_df[\"Span_text\"])\n",
    "\n",
    "    return entity_details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>Entity</th>\n",
       "      <th>tag</th>\n",
       "      <th>Wikidata_id</th>\n",
       "      <th>Wikidata_url</th>\n",
       "      <th>Span</th>\n",
       "      <th>Span_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>6279</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q6279</td>\n",
       "      <td>(Joe, Biden)</td>\n",
       "      <td>Joe Biden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>letter</td>\n",
       "      <td>None</td>\n",
       "      <td>133492</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q133492</td>\n",
       "      <td>(message)</td>\n",
       "      <td>message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>audience</td>\n",
       "      <td>None</td>\n",
       "      <td>211198</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q211198</td>\n",
       "      <td>(public)</td>\n",
       "      <td>public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>scandal</td>\n",
       "      <td>None</td>\n",
       "      <td>192909</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q192909</td>\n",
       "      <td>(scandal)</td>\n",
       "      <td>scandal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>vice president</td>\n",
       "      <td>None</td>\n",
       "      <td>42178</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q42178</td>\n",
       "      <td>(vice, president)</td>\n",
       "      <td>vice president</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year           type          Entity     tag  Wikidata_id  \\\n",
       "16  2019  News and blog       Joe Biden  PERSON         6279   \n",
       "16  2019  News and blog          letter    None       133492   \n",
       "16  2019  News and blog        audience    None       211198   \n",
       "16  2019  News and blog         scandal    None       192909   \n",
       "16  2019  News and blog  vice president    None        42178   \n",
       "\n",
       "                             Wikidata_url               Span       Span_text  \n",
       "16    https://www.wikidata.org/wiki/Q6279       (Joe, Biden)       Joe Biden  \n",
       "16  https://www.wikidata.org/wiki/Q133492          (message)         message  \n",
       "16  https://www.wikidata.org/wiki/Q211198           (public)          public  \n",
       "16  https://www.wikidata.org/wiki/Q192909          (scandal)         scandal  \n",
       "16   https://www.wikidata.org/wiki/Q42178  (vice, president)  vice president  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_entity_details_df = get_entity_details_df(dataset_df, \"text_doc\")\n",
    "text_entity_details_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>Entity</th>\n",
       "      <th>tag</th>\n",
       "      <th>Wikidata_id</th>\n",
       "      <th>Wikidata_url</th>\n",
       "      <th>Span</th>\n",
       "      <th>Span_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>6279</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q6279</td>\n",
       "      <td>(Joe, Biden)</td>\n",
       "      <td>Joe Biden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>agency</td>\n",
       "      <td>None</td>\n",
       "      <td>3951828</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q3951828</td>\n",
       "      <td>(Thoughts)</td>\n",
       "      <td>Thoughts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Straight</td>\n",
       "      <td>None</td>\n",
       "      <td>7620981</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q7620981</td>\n",
       "      <td>(Straight)</td>\n",
       "      <td>Straight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Tom Selleck</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>213706</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q213706</td>\n",
       "      <td>(Tom, Selleck)</td>\n",
       "      <td>Tom Selleck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>You</td>\n",
       "      <td>None</td>\n",
       "      <td>39082126</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q39082126</td>\n",
       "      <td>(You)</td>\n",
       "      <td>You</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year           type       Entity     tag  Wikidata_id  \\\n",
       "16  2019  News and blog    Joe Biden  PERSON         6279   \n",
       "16  2019  News and blog       agency    None      3951828   \n",
       "16  2019  News and blog     Straight    None      7620981   \n",
       "19  2019  News and blog  Tom Selleck  PERSON       213706   \n",
       "19  2019  News and blog          You    None     39082126   \n",
       "\n",
       "                               Wikidata_url            Span    Span_text  \n",
       "16      https://www.wikidata.org/wiki/Q6279    (Joe, Biden)    Joe Biden  \n",
       "16   https://www.wikidata.org/wiki/Q3951828      (Thoughts)     Thoughts  \n",
       "16   https://www.wikidata.org/wiki/Q7620981      (Straight)     Straight  \n",
       "19    https://www.wikidata.org/wiki/Q213706  (Tom, Selleck)  Tom Selleck  \n",
       "19  https://www.wikidata.org/wiki/Q39082126           (You)          You  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_entity_details_df = get_entity_details_df(dataset_df, \"headline_doc\")\n",
    "headline_entity_details_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AH8Yysi3AllK"
   },
   "source": [
    "## Group dataframes by year and count named entities\n",
    "Currently, entityLinker catches all entities, not just proper nouns. To get around this, we first create dataframes filtering by year, then get the POS tags using spacy. This will then allow us to filter the dataframes further by excluding any counted nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XVTMgcPR7yx7"
   },
   "outputs": [],
   "source": [
    "def get_count(df: pd.DataFrame):\n",
    "  copied_df = df.copy()\n",
    "  copied_df['Count'] = copied_df.groupby(['Wikidata_id'])['Wikidata_id'].transform('count')\n",
    "  sorted_df = copied_df.sort_values(by=['Count'], ascending=False)\n",
    "  unique_df = sorted_df.drop_duplicates(subset=[\"Wikidata_id\"])\n",
    "\n",
    "  return unique_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "br0e4lxp12Sb"
   },
   "outputs": [],
   "source": [
    "tagger = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting entity counts and keeping only proper nouns to get rid of common regular words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_years_dfs(df: pd.DataFrame):\n",
    "    years, years_dfs = get_groups(df, \"year\")\n",
    "\n",
    "    year_counts_dfs = [get_count(df) for df in years_dfs]\n",
    "\n",
    "    for df in year_counts_dfs:\n",
    "        df['POS'] = [doc[0].pos_ for doc in tagger.pipe(df['Entity'])]\n",
    "    \n",
    "    propn_year_counts_dfs = [df[df[\"POS\"] == \"PROPN\"] for df in year_counts_dfs]\n",
    "\n",
    "    return years, propn_year_counts_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>Entity</th>\n",
       "      <th>tag</th>\n",
       "      <th>Wikidata_id</th>\n",
       "      <th>Wikidata_url</th>\n",
       "      <th>Span</th>\n",
       "      <th>Span_text</th>\n",
       "      <th>Count</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>GPE</td>\n",
       "      <td>30</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q30</td>\n",
       "      <td>(U.S.)</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>49</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>NORP</td>\n",
       "      <td>22686</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q22686</td>\n",
       "      <td>(Trump)</td>\n",
       "      <td>Trump</td>\n",
       "      <td>26</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>NORP</td>\n",
       "      <td>29552</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q29552</td>\n",
       "      <td>(Democrats)</td>\n",
       "      <td>Democrats</td>\n",
       "      <td>22</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Andrew John Henry Way</td>\n",
       "      <td>None</td>\n",
       "      <td>17641254</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q17641254</td>\n",
       "      <td>(way)</td>\n",
       "      <td>way</td>\n",
       "      <td>20</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Corazon Aquino</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>1480</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q1480</td>\n",
       "      <td>(Cory)</td>\n",
       "      <td>Cory</td>\n",
       "      <td>20</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year           type                    Entity     tag  Wikidata_id  \\\n",
       "53    2019  News and blog  United States of America     GPE           30   \n",
       "40    2019  News and blog              Donald Trump    NORP        22686   \n",
       "2347  2019  News and blog          Democratic Party    NORP        29552   \n",
       "2347  2019  News and blog     Andrew John Henry Way    None     17641254   \n",
       "1919  2019  News and blog            Corazon Aquino  PERSON         1480   \n",
       "\n",
       "                                 Wikidata_url         Span  Span_text  Count  \\\n",
       "53          https://www.wikidata.org/wiki/Q30       (U.S.)       U.S.     49   \n",
       "40       https://www.wikidata.org/wiki/Q22686      (Trump)      Trump     26   \n",
       "2347     https://www.wikidata.org/wiki/Q29552  (Democrats)  Democrats     22   \n",
       "2347  https://www.wikidata.org/wiki/Q17641254        (way)        way     20   \n",
       "1919      https://www.wikidata.org/wiki/Q1480       (Cory)       Cory     20   \n",
       "\n",
       "        POS  \n",
       "53    PROPN  \n",
       "40    PROPN  \n",
       "2347  PROPN  \n",
       "2347  PROPN  \n",
       "1919  PROPN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_text, years_text_dfs = get_years_dfs(text_entity_details_df)\n",
    "years_text_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>Entity</th>\n",
       "      <th>tag</th>\n",
       "      <th>Wikidata_id</th>\n",
       "      <th>Wikidata_url</th>\n",
       "      <th>Span</th>\n",
       "      <th>Span_text</th>\n",
       "      <th>Count</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>None</td>\n",
       "      <td>22686</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q22686</td>\n",
       "      <td>(Trump)</td>\n",
       "      <td>Trump</td>\n",
       "      <td>4</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>6279</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q6279</td>\n",
       "      <td>(Joe, Biden)</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>2</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Alexandria Ocasio-Cortez</td>\n",
       "      <td>None</td>\n",
       "      <td>55223040</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q55223040</td>\n",
       "      <td>(Ocasio, -, Cortez)</td>\n",
       "      <td>Ocasio-Cortez</td>\n",
       "      <td>2</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Ebola virus disease</td>\n",
       "      <td>None</td>\n",
       "      <td>51993</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q51993</td>\n",
       "      <td>(Ebola)</td>\n",
       "      <td>Ebola</td>\n",
       "      <td>1</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>2019</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>George Soros</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>12908</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q12908</td>\n",
       "      <td>(George, Soros)</td>\n",
       "      <td>George Soros</td>\n",
       "      <td>1</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year           type                    Entity     tag  Wikidata_id  \\\n",
       "2352  2019  News and blog              Donald Trump    None        22686   \n",
       "16    2019  News and blog                 Joe Biden  PERSON         6279   \n",
       "2351  2019  News and blog  Alexandria Ocasio-Cortez    None     55223040   \n",
       "21    2019  News and blog       Ebola virus disease    None        51993   \n",
       "2333  2019  News and blog              George Soros  PERSON        12908   \n",
       "\n",
       "                                 Wikidata_url                 Span  \\\n",
       "2352     https://www.wikidata.org/wiki/Q22686              (Trump)   \n",
       "16        https://www.wikidata.org/wiki/Q6279         (Joe, Biden)   \n",
       "2351  https://www.wikidata.org/wiki/Q55223040  (Ocasio, -, Cortez)   \n",
       "21       https://www.wikidata.org/wiki/Q51993              (Ebola)   \n",
       "2333     https://www.wikidata.org/wiki/Q12908      (George, Soros)   \n",
       "\n",
       "          Span_text  Count    POS  \n",
       "2352          Trump      4  PROPN  \n",
       "16        Joe Biden      2  PROPN  \n",
       "2351  Ocasio-Cortez      2  PROPN  \n",
       "21            Ebola      1  PROPN  \n",
       "2333   George Soros      1  PROPN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_headline, years_headline_dfs = get_years_dfs(headline_entity_details_df)\n",
    "years_headline_dfs[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dx7K1TwSorck"
   },
   "source": [
    "## Write results to Excel spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_entity_counts_for_years(years: list[int], dfs: list[pd.DataFrame], output_path: str):\n",
    "    writer = pd.ExcelWriter(output_path, engine=\"xlsxwriter\")\n",
    "    \n",
    "    for year, df in zip(years, dfs):\n",
    "        df.to_excel(\n",
    "            writer,\n",
    "            sheet_name=str(year),\n",
    "            index=False,\n",
    "            columns=[\"Entity\", \"tag\", \"Wikidata_id\", \"Wikidata_url\", \"Span_text\", \"Count\"]\n",
    "        )\n",
    "    \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_entity_counts_for_years(\n",
    "    years=years_text, \n",
    "    dfs=years_text_dfs, \n",
    "    output_path=make_output_path(using_dataset, \"named_entities_frequency\")\n",
    ")\n",
    "\n",
    "save_entity_counts_for_years(\n",
    "    years=years_headline, \n",
    "    dfs=years_headline_dfs, \n",
    "    output_path=make_output_path(using_dataset, \"named_entities_frequency_headlines\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_entity_counts_for_types(entity_details_df: pd.DataFrame, suffix = \"\"):\n",
    "    types, types_dfs = get_groups(entity_details_df, \"type\")\n",
    "\n",
    "    for type, df in zip(types, types_dfs):\n",
    "        years_text, years_text_dfs = get_years_dfs(df)\n",
    "\n",
    "        save_entity_counts_for_years(\n",
    "            years=years_text, \n",
    "            dfs=years_text_dfs, \n",
    "            output_path=make_output_path_for_type(using_dataset, type, f\"named_entities_frequency{suffix}\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_entity_counts_for_types(text_entity_details_df)\n",
    "save_entity_counts_for_types(headline_entity_details_df, \"_headlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOPZdSsADjp2P11jYW7Zcpa",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
