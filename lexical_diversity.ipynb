{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9047e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens.doc import Doc\n",
    "import pandas as pd\n",
    "from dataset_config import BASE_FAKESPEAK_CONFIG, BASE_MISINFOTEXT_CONFIG\n",
    "from helpers import get_groups, make_output_path, make_output_path_for_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecbb22f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fakespeak_config = BASE_FAKESPEAK_CONFIG | {\n",
    "    \"save_cols\": [BASE_FAKESPEAK_CONFIG[\"id_col\"], \"lexical_diversity\"]\n",
    "}\n",
    "\n",
    "misinfotext_config = BASE_MISINFOTEXT_CONFIG | {\n",
    "    \"save_cols\": [BASE_MISINFOTEXT_CONFIG[\"id_col\"], \"lexical_diversity\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "497984c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "using_dataset = fakespeak_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_excel(\n",
    "    using_dataset[\"input_path\"], \n",
    "    sheet_name=using_dataset[\"sheet_name\"], \n",
    "    usecols=using_dataset[\"usecols\"]\n",
    ")\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28e0e13",
   "metadata": {},
   "source": [
    "## Calculating lexical diversity using spacy\n",
    "\n",
    "Lexical diversity is calculated by number of types (unique lemmas) divided by number of tokens (total words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "099b0097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adam\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\site-packages\\coreferee\\manager.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d54c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df[\"doc\"] = list(nlp.pipe(dataset_df[using_dataset[\"text_col\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d37877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lexical_diversity(doc: Doc):\n",
    "    tokens = [token for token in doc if token.is_alpha]\n",
    "\n",
    "    if len(tokens) == 0:\n",
    "        return 0\n",
    "    \n",
    "    types = set(token.lemma_ for token in doc if token.is_alpha)\n",
    "\n",
    "    return len(types) / len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a81c0d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>combinedLabel</th>\n",
       "      <th>originalTextType</th>\n",
       "      <th>originalBodyText</th>\n",
       "      <th>originalDateYear</th>\n",
       "      <th>doc</th>\n",
       "      <th>lexical_diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Politifact_FALSE_Social media_687276</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Mexico is paying for the Wall through the new ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>(Mexico, is, paying, for, the, Wall, through, ...</td>\n",
       "      <td>0.795918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Politifact_FALSE_Social media_25111</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Chuck Schumer: \"why should American citizens b...</td>\n",
       "      <td>2019</td>\n",
       "      <td>(Chuck, Schumer, :, \", why, should, American, ...</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Politifact_FALSE_Social media_735424</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Billions of dollars are sent to the State of C...</td>\n",
       "      <td>2019</td>\n",
       "      <td>(Billions, of, dollars, are, sent, to, the, St...</td>\n",
       "      <td>0.851064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Politifact_FALSE_Social media_594307</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>If 50 Billion $$ were set aside to go towards ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>(If, 50, Billion, $, $, were, set, aside, to, ...</td>\n",
       "      <td>0.743590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Politifact_FALSE_Social media_839325</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Huge@#CD 9 news. \\n@ncsbe\\n sent letter to eve...</td>\n",
       "      <td>2019</td>\n",
       "      <td>(Huge@#CD, 9, news, ., \\n, @ncsbe, \\n , sent, ...</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>Politifact_Pants on Fire_Social media_876628</td>\n",
       "      <td>Pants on Fire</td>\n",
       "      <td>Social media</td>\n",
       "      <td>A great lesson in Optics 101: The Monroe Doctr...</td>\n",
       "      <td>2023</td>\n",
       "      <td>(A, great, lesson, in, Optics, 101, :, The, Mo...</td>\n",
       "      <td>0.433148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>Politifact_Pants on Fire_Social media_231170</td>\n",
       "      <td>Pants on Fire</td>\n",
       "      <td>Social media</td>\n",
       "      <td>“One of these Joe’s is not like the other… one...</td>\n",
       "      <td>2023</td>\n",
       "      <td>(“, One, of, these, Joe, ’s, is, not, like, th...</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>Politifact_Pants on Fire_Social media_874359</td>\n",
       "      <td>Pants on Fire</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Autopsies Prove that COVID-19 is a Disseminate...</td>\n",
       "      <td>2020</td>\n",
       "      <td>(Autopsies, Prove, that, COVID-19, is, a, Diss...</td>\n",
       "      <td>0.444109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>Politifact_Pants on Fire_Social media_635418</td>\n",
       "      <td>Pants on Fire</td>\n",
       "      <td>Social media</td>\n",
       "      <td>She collapsed when she saw jfk jr. as she was ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>(She, collapsed, when, she, saw, jfk, jr, ., a...</td>\n",
       "      <td>0.776316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>Politifact_Pants on Fire_Social media_621529</td>\n",
       "      <td>Pants on Fire</td>\n",
       "      <td>Social media</td>\n",
       "      <td>ANYBODY ELSE FIND IT FUNNY THAT ISRAEL WAS ATT...</td>\n",
       "      <td>2023</td>\n",
       "      <td>(ANYBODY, ELSE, FIND, IT, FUNNY, THAT, ISRAEL,...</td>\n",
       "      <td>0.826923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2961 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                ID  combinedLabel  \\\n",
       "0             Politifact_FALSE_Social media_687276          False   \n",
       "1              Politifact_FALSE_Social media_25111          False   \n",
       "2             Politifact_FALSE_Social media_735424          False   \n",
       "3             Politifact_FALSE_Social media_594307          False   \n",
       "4             Politifact_FALSE_Social media_839325          False   \n",
       "...                                            ...            ...   \n",
       "2956  Politifact_Pants on Fire_Social media_876628  Pants on Fire   \n",
       "2957  Politifact_Pants on Fire_Social media_231170  Pants on Fire   \n",
       "2958  Politifact_Pants on Fire_Social media_874359  Pants on Fire   \n",
       "2959  Politifact_Pants on Fire_Social media_635418  Pants on Fire   \n",
       "2960  Politifact_Pants on Fire_Social media_621529  Pants on Fire   \n",
       "\n",
       "     originalTextType                                   originalBodyText  \\\n",
       "0        Social media  Mexico is paying for the Wall through the new ...   \n",
       "1        Social media  Chuck Schumer: \"why should American citizens b...   \n",
       "2        Social media  Billions of dollars are sent to the State of C...   \n",
       "3        Social media  If 50 Billion $$ were set aside to go towards ...   \n",
       "4        Social media  Huge@#CD 9 news. \\n@ncsbe\\n sent letter to eve...   \n",
       "...               ...                                                ...   \n",
       "2956     Social media  A great lesson in Optics 101: The Monroe Doctr...   \n",
       "2957     Social media  “One of these Joe’s is not like the other… one...   \n",
       "2958     Social media  Autopsies Prove that COVID-19 is a Disseminate...   \n",
       "2959     Social media  She collapsed when she saw jfk jr. as she was ...   \n",
       "2960     Social media  ANYBODY ELSE FIND IT FUNNY THAT ISRAEL WAS ATT...   \n",
       "\n",
       "      originalDateYear                                                doc  \\\n",
       "0                 2019  (Mexico, is, paying, for, the, Wall, through, ...   \n",
       "1                 2019  (Chuck, Schumer, :, \", why, should, American, ...   \n",
       "2                 2019  (Billions, of, dollars, are, sent, to, the, St...   \n",
       "3                 2019  (If, 50, Billion, $, $, were, set, aside, to, ...   \n",
       "4                 2019  (Huge@#CD, 9, news, ., \\n, @ncsbe, \\n , sent, ...   \n",
       "...                ...                                                ...   \n",
       "2956              2023  (A, great, lesson, in, Optics, 101, :, The, Mo...   \n",
       "2957              2023  (“, One, of, these, Joe, ’s, is, not, like, th...   \n",
       "2958              2020  (Autopsies, Prove, that, COVID-19, is, a, Diss...   \n",
       "2959              2021  (She, collapsed, when, she, saw, jfk, jr, ., a...   \n",
       "2960              2023  (ANYBODY, ELSE, FIND, IT, FUNNY, THAT, ISRAEL,...   \n",
       "\n",
       "      lexical_diversity  \n",
       "0              0.795918  \n",
       "1              0.650000  \n",
       "2              0.851064  \n",
       "3              0.743590  \n",
       "4              0.828571  \n",
       "...                 ...  \n",
       "2956           0.433148  \n",
       "2957           0.687500  \n",
       "2958           0.444109  \n",
       "2959           0.776316  \n",
       "2960           0.826923  \n",
       "\n",
       "[2961 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df[\"lexical_diversity\"] = dataset_df[\"doc\"].apply(calculate_lexical_diversity)\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99e51d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>combinedLabel</th>\n",
       "      <th>originalTextType</th>\n",
       "      <th>originalBodyText</th>\n",
       "      <th>originalDateYear</th>\n",
       "      <th>doc</th>\n",
       "      <th>lexical_diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Politifact_FALSE_Social media_687276</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Mexico is paying for the Wall through the new ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>(Mexico, is, paying, for, the, Wall, through, ...</td>\n",
       "      <td>0.795918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Politifact_FALSE_Social media_25111</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Chuck Schumer: \"why should American citizens b...</td>\n",
       "      <td>2019</td>\n",
       "      <td>(Chuck, Schumer, :, \", why, should, American, ...</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Politifact_FALSE_Social media_735424</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Billions of dollars are sent to the State of C...</td>\n",
       "      <td>2019</td>\n",
       "      <td>(Billions, of, dollars, are, sent, to, the, St...</td>\n",
       "      <td>0.851064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Politifact_FALSE_Social media_594307</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>If 50 Billion $$ were set aside to go towards ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>(If, 50, Billion, $, $, were, set, aside, to, ...</td>\n",
       "      <td>0.743590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Politifact_FALSE_Social media_839325</td>\n",
       "      <td>False</td>\n",
       "      <td>Social media</td>\n",
       "      <td>Huge@#CD 9 news. \\n@ncsbe\\n sent letter to eve...</td>\n",
       "      <td>2019</td>\n",
       "      <td>(Huge@#CD, 9, news, ., \\n, @ncsbe, \\n , sent, ...</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID combinedLabel originalTextType  \\\n",
       "0  Politifact_FALSE_Social media_687276         False     Social media   \n",
       "1   Politifact_FALSE_Social media_25111         False     Social media   \n",
       "2  Politifact_FALSE_Social media_735424         False     Social media   \n",
       "3  Politifact_FALSE_Social media_594307         False     Social media   \n",
       "4  Politifact_FALSE_Social media_839325         False     Social media   \n",
       "\n",
       "                                    originalBodyText  originalDateYear  \\\n",
       "0  Mexico is paying for the Wall through the new ...              2019   \n",
       "1  Chuck Schumer: \"why should American citizens b...              2019   \n",
       "2  Billions of dollars are sent to the State of C...              2019   \n",
       "3  If 50 Billion $$ were set aside to go towards ...              2019   \n",
       "4  Huge@#CD 9 news. \\n@ncsbe\\n sent letter to eve...              2019   \n",
       "\n",
       "                                                 doc  lexical_diversity  \n",
       "0  (Mexico, is, paying, for, the, Wall, through, ...           0.795918  \n",
       "1  (Chuck, Schumer, :, \", why, should, American, ...           0.650000  \n",
       "2  (Billions, of, dollars, are, sent, to, the, St...           0.851064  \n",
       "3  (If, 50, Billion, $, $, were, set, aside, to, ...           0.743590  \n",
       "4  (Huge@#CD, 9, news, ., \\n, @ncsbe, \\n , sent, ...           0.828571  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years, years_dfs = get_groups(dataset_df, using_dataset[\"year_col\"])\n",
    "years_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fc8b086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>combinedLabel</th>\n",
       "      <th>originalTextType</th>\n",
       "      <th>originalBodyText</th>\n",
       "      <th>originalDateYear</th>\n",
       "      <th>doc</th>\n",
       "      <th>lexical_diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Politifact_FALSE_News and blog_73653</td>\n",
       "      <td>False</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Joe Biden has a message for the public on his ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>(Joe, Biden, has, a, message, for, the, public...</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Politifact_FALSE_News and blog_605527</td>\n",
       "      <td>False</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Hollywood legend Tom Selleck has praised Donal...</td>\n",
       "      <td>2019</td>\n",
       "      <td>(Hollywood, legend, Tom, Selleck, has, praised...</td>\n",
       "      <td>0.517857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Politifact_FALSE_News and blog_868147</td>\n",
       "      <td>False</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Hundreds of Congolese migrants, with who knows...</td>\n",
       "      <td>2019</td>\n",
       "      <td>(Hundreds, of, Congolese, migrants, ,, with, w...</td>\n",
       "      <td>0.513575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Politifact_FALSE_News and blog_944705</td>\n",
       "      <td>False</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>David Steinberg released his latest report on ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>(David, Steinberg, released, his, latest, repo...</td>\n",
       "      <td>0.606796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Politifact_FALSE_News and blog_691427</td>\n",
       "      <td>False</td>\n",
       "      <td>News and blog</td>\n",
       "      <td>Nancy Pelosi is neck deep in Ukraine politics....</td>\n",
       "      <td>2019</td>\n",
       "      <td>(Nancy, Pelosi, is, neck, deep, in, Ukraine, p...</td>\n",
       "      <td>0.474104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       ID combinedLabel originalTextType  \\\n",
       "16   Politifact_FALSE_News and blog_73653         False    News and blog   \n",
       "19  Politifact_FALSE_News and blog_605527         False    News and blog   \n",
       "21  Politifact_FALSE_News and blog_868147         False    News and blog   \n",
       "25  Politifact_FALSE_News and blog_944705         False    News and blog   \n",
       "40  Politifact_FALSE_News and blog_691427         False    News and blog   \n",
       "\n",
       "                                     originalBodyText  originalDateYear  \\\n",
       "16  Joe Biden has a message for the public on his ...              2019   \n",
       "19  Hollywood legend Tom Selleck has praised Donal...              2019   \n",
       "21  Hundreds of Congolese migrants, with who knows...              2019   \n",
       "25  David Steinberg released his latest report on ...              2019   \n",
       "40  Nancy Pelosi is neck deep in Ukraine politics....              2019   \n",
       "\n",
       "                                                  doc  lexical_diversity  \n",
       "16  (Joe, Biden, has, a, message, for, the, public...           0.793651  \n",
       "19  (Hollywood, legend, Tom, Selleck, has, praised...           0.517857  \n",
       "21  (Hundreds, of, Congolese, migrants, ,, with, w...           0.513575  \n",
       "25  (David, Steinberg, released, his, latest, repo...           0.606796  \n",
       "40  (Nancy, Pelosi, is, neck, deep, in, Ukraine, p...           0.474104  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types, types_dfs = get_groups(dataset_df, using_dataset[\"type_col\"])\n",
    "types_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7714bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_df(dfs: list[pd.DataFrame], years: list[int]):\n",
    "    return pd.DataFrame(\n",
    "        [df[\"lexical_diversity\"].describe() for df in dfs],\n",
    "        index=pd.Index(data=years, name=\"year\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78d0c0a",
   "metadata": {},
   "source": [
    "## Writing dataframes to excel spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ac2ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_years(writer: pd.ExcelWriter, years: list[int], dfs: list[pd.DataFrame]):\n",
    "    for year, df in zip(years, dfs):\n",
    "        df.to_excel(\n",
    "            writer,\n",
    "            sheet_name=str(year),\n",
    "            index=False,\n",
    "            columns=using_dataset[\"save_cols\"]\n",
    "        )\n",
    "\n",
    "    summary_df = get_summary_df(dfs, years)\n",
    "    summary_df.to_excel(writer, sheet_name=\"Summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "059698c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = make_output_path(using_dataset, \"lexical_diversity\")\n",
    "\n",
    "writer = pd.ExcelWriter(output_path, engine=\"xlsxwriter\")\n",
    "save_years(writer, years, years_dfs)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a254e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for type, df in zip(types, types_dfs):\n",
    "    years, years_dfs = get_groups(df, using_dataset[\"year_col\"])\n",
    "\n",
    "    output_path = make_output_path_for_type(using_dataset, type, \"lexical_diversity\")\n",
    "\n",
    "    writer = pd.ExcelWriter(output_path, engine=\"xlsxwriter\")\n",
    "    save_years(writer, years, years_dfs)\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
