{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPFsr_9hlORo"
      },
      "source": [
        "# Notebook for Parts of Speech Analysis\n",
        "\n",
        "Using spaCy for parts of speech analysis, we want to create relative frequency tables for the parts of speech by year.\n",
        "\n",
        "Currently processes the \"Fakespeak-ENG modified.xlsx\" file (I've renamed my copy to \"Fakespeak_ENG_modified.xlsx\" to create a more consistent path), but will eventually be run on data from MisInfoText as well.\n",
        "\n",
        "From the original data file, we use the following columns: ID, combinedLabel, originalTextType, originalBodyText, originalDateYear\n",
        "\n",
        "We are processing text from the \"originalBodyText\" column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2nH7fSVElJ8g"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.tokens.doc import Doc\n",
        "from spacy.tokens.token import Token\n",
        "import pandas as pd\n",
        "from dataset_config import BASE_FAKESPEAK_CONFIG, BASE_MISINFOTEXT_CONFIG\n",
        "from helpers import get_groups, make_output_path, make_output_path_for_type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uvTFrdcslth"
      },
      "source": [
        "## Loading articles into dataframes, separated by year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "fakespeak_config = BASE_FAKESPEAK_CONFIG\n",
        "misinfotext_config = BASE_MISINFOTEXT_CONFIG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "using_dataset = fakespeak_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>combinedLabel</th>\n",
              "      <th>originalTextType</th>\n",
              "      <th>originalBodyText</th>\n",
              "      <th>originalDateYear</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Politifact_FALSE_Social media_687276</td>\n",
              "      <td>False</td>\n",
              "      <td>Social media</td>\n",
              "      <td>Mexico is paying for the Wall through the new ...</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Politifact_FALSE_Social media_25111</td>\n",
              "      <td>False</td>\n",
              "      <td>Social media</td>\n",
              "      <td>Chuck Schumer: \"why should American citizens b...</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Politifact_FALSE_Social media_735424</td>\n",
              "      <td>False</td>\n",
              "      <td>Social media</td>\n",
              "      <td>Billions of dollars are sent to the State of C...</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Politifact_FALSE_Social media_594307</td>\n",
              "      <td>False</td>\n",
              "      <td>Social media</td>\n",
              "      <td>If 50 Billion $$ were set aside to go towards ...</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Politifact_FALSE_Social media_839325</td>\n",
              "      <td>False</td>\n",
              "      <td>Social media</td>\n",
              "      <td>Huge@#CD 9 news. \\n@ncsbe\\n sent letter to eve...</td>\n",
              "      <td>2019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     ID combinedLabel originalTextType  \\\n",
              "0  Politifact_FALSE_Social media_687276         False     Social media   \n",
              "1   Politifact_FALSE_Social media_25111         False     Social media   \n",
              "2  Politifact_FALSE_Social media_735424         False     Social media   \n",
              "3  Politifact_FALSE_Social media_594307         False     Social media   \n",
              "4  Politifact_FALSE_Social media_839325         False     Social media   \n",
              "\n",
              "                                    originalBodyText  originalDateYear  \n",
              "0  Mexico is paying for the Wall through the new ...              2019  \n",
              "1  Chuck Schumer: \"why should American citizens b...              2019  \n",
              "2  Billions of dollars are sent to the State of C...              2019  \n",
              "3  If 50 Billion $$ were set aside to go towards ...              2019  \n",
              "4  Huge@#CD 9 news. \\n@ncsbe\\n sent letter to eve...              2019  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_df = pd.read_excel(\n",
        "    using_dataset[\"input_path\"], \n",
        "    sheet_name=using_dataset[\"sheet_name\"], \n",
        "    usecols=using_dataset[\"usecols\"]\n",
        ")\n",
        "\n",
        "# Removing 2007 and 2008 years because little data in them\n",
        "dataset_df = dataset_df[~(dataset_df[using_dataset[\"year_col\"]] == 2007) & ~(dataset_df[using_dataset[\"year_col\"]] == 2008)]\n",
        "\n",
        "dataset_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVjz0URmxhZB"
      },
      "source": [
        "## Tagging parts of speech using spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHjWNe6IAEDx"
      },
      "source": [
        "Using the small English web model, we tag the parts of speech in the body text by making article's body text a string, analyzing the string using spaCy, and then appending each token to a list manually.\n",
        "\n",
        "We end up with a dataframe of many rows since each tag/tagged token takes up one row - this is fine since we are looking at overall counts in a year and we don't need to preserve the delineation between articles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_tokens(doc: Doc):\n",
        "    return [token for token in doc]\n",
        "\n",
        "def get_pos(token: Token):\n",
        "    return token.pos_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_df[\"doc\"] = list(nlp.pipe(dataset_df[using_dataset[\"text_col\"]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_df[\"token\"] = dataset_df[\"doc\"].apply(get_tokens)\n",
        "pos_df = dataset_df.explode(\"token\")\n",
        "pos_df[\"POS\"] = pos_df[\"token\"].apply(get_pos)\n",
        "pos_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YznSANUdOqfu"
      },
      "source": [
        "## Create relative frequency tables of parts of speech by year"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Frequency tables per year for saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "years, years_dfs = get_groups(pos_df, using_dataset[\"year_col\"])\n",
        "years_dfs[0].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary tables for easy glancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_summary_counts_df(years: list[int], years_dfs: list[pd.DataFrame]):\n",
        "    return pd.DataFrame(\n",
        "        data=[df[\"POS\"].value_counts() for df in years_dfs], \n",
        "        index=pd.Index(years, name=\"year\")\n",
        "    )\n",
        "\n",
        "def get_summary_proportions_df(years: list[int], years_dfs: list[pd.DataFrame]):\n",
        "    return pd.DataFrame(\n",
        "        data=[df[\"POS\"].value_counts(normalize=True) for df in years_dfs], \n",
        "        index=pd.Index(years, name=\"year\")\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary_counts_df = get_summary_counts_df(years, years_dfs)\n",
        "summary_counts_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary_proportions_df = get_summary_proportions_df(years, years_dfs)\n",
        "summary_proportions_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "types, types_dfs = get_groups(pos_df, using_dataset[\"type_col\"])\n",
        "types_dfs[0].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_pos_table_for_year(df: pd.DataFrame):\n",
        "    counts = df[\"POS\"].value_counts()\n",
        "\n",
        "    pos_table = counts.to_frame()\n",
        "    pos_table[\"proportion\"] = counts / counts.sum()\n",
        "\n",
        "    return pos_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_years(writer: pd.ExcelWriter, years: list[int], years_dfs: list[pd.DataFrame]):\n",
        "    for year, df in zip(years, years_dfs):\n",
        "        pos_table_df = get_pos_table_for_year(df)\n",
        "        pos_table_df.to_excel(\n",
        "            writer,\n",
        "            sheet_name=str(year)\n",
        "        )\n",
        "    \n",
        "    get_summary_counts_df(years, years_dfs).to_excel(writer, sheet_name=\"counts\")\n",
        "    get_summary_proportions_df(years, years_dfs).to_excel(writer, sheet_name=\"proportions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKnspFqdzJ7q"
      },
      "source": [
        "## Writing dataframes to excel spreadsheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_path = make_output_path(using_dataset, \"POS_frequency\")\n",
        "\n",
        "writer = pd.ExcelWriter(output_path, engine=\"xlsxwriter\")\n",
        "save_years(writer, years, years_dfs)\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for type, df in zip(types, types_dfs):\n",
        "    years, years_dfs = get_groups(df, using_dataset[\"year_col\"])\n",
        "\n",
        "    output_path = make_output_path_for_type(using_dataset, type, \"POS_frequency\")\n",
        "\n",
        "    writer = pd.ExcelWriter(output_path, engine=\"xlsxwriter\")\n",
        "    save_years(writer, years, years_dfs)\n",
        "    writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
